{
    "version": "https://jsonfeed.org/version/1",
    "title": "Security Advisory for Go modules",
    "home_page_url": "https://github.com/advisories?query=type%3Areviewed+ecosystem%3Ago",
    "feed_url": "https://azu.github.io/github-advisory-database-rss/go.json",
    "description": "Security Advisory for Go modules on GitHub",
    "items": [
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>When run as a server, OPA exposes an HTTP<a href=\"https://www.openpolicyagent.org/docs/latest/rest-api/#data-api\"> Data API</a> for reading and writing documents. Requesting a virtual document through the Data API entails policy evaluation, where a Rego query containing a single data document <a href=\"https://www.openpolicyagent.org/docs/latest/policy-language/#references\">reference</a> is constructed from the requested path. This query is then used for policy evaluation.</p>\n<p>A HTTP request path can be crafted in a way that injects Rego code into the constructed query. The evaluation result cannot be made to return any other data than what is generated by the requested path, but this path can be misdirected, and the injected Rego code can be crafted to make the query succeed or fail; opening up for oracle attacks or, given the right circumstances, erroneous policy decision results. Furthermore, the injected code can be crafted to be computationally expensive, resulting in a Denial Of Service (DoS) attack.</p>\n<p><strong>Users are only impacted if all of the following apply:</strong></p>\n<ul>\n<li>OPA is deployed as a standalone server (rather than being used as a Go library)</li>\n<li>The OPA server is exposed outside of the local host in an untrusted environment.</li>\n<li>The configured <a href=\"https://www.openpolicyagent.org/docs/latest/security/#authentication-and-authorization\">authorization policy</a> does not do exact matching of the <code>input.path</code> attribute when deciding if the request should be allowed.</li>\n</ul>\n<p><strong>or, if all of the following apply:</strong></p>\n<ul>\n<li>OPA is deployed as a standalone server.</li>\n<li>The service connecting to OPA allows 3rd parties to insert unsanitised text into the path of the HTTP request to OPA’s Data API.</li>\n</ul>\n<p><strong>Note:</strong> With <strong>no</strong> Authorization Policy configured for restricting API access (the default configuration), the RESTful Data API provides access for managing Rego policies; and the RESTful Query API facilitates advanced queries. Full access to these APIs provides both simpler, and broader access than what the security issue describes here can facilitate. As such, OPA servers exposed to a network are <strong>not</strong> considered affected by the attack described here if they are knowingly not restricting access through an Authorization Policy.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Fixed in OPA v1.4.0.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<h4 id=\"dont-publicly-expose-opas-restful-apis\">Don’t publicly expose OPA’s RESTful APIs</h4>\n<p>Unless necessary for production reasons, network access to OPA’s RESTful APIs should be limited to <code>localhost</code> and/or trusted networks. \nSince OPA v1.0, unless otherwise configured, the server listener defaults to <code>localhost</code>.</p>\n<h4 id=\"enable-authentication-to-only-allow-access-to-trusted-clients\">Enable Authentication to Only Allow Access to Trusted Clients</h4>\n<p>A configured <a href=\"https://www.openpolicyagent.org/docs/latest/security/#authentication-and-authorization\">authentication</a> scheme is a requirement when OPA is exposed in an untrusted environment. While requiring authentication alone doesn’t mitigate this attack, it effectively reduces the scope from untrusted clients to trusted clients.</p>\n<h4 id=\"perform-path-validation-using-opas-authorization-policy-functionality\">Perform Path Validation Using OPA’s Authorization Policy Functionality</h4>\n<p>OPA can be configured to use an <a href=\"https://www.openpolicyagent.org/docs/latest/security/#authentication-and-authorization\">Authorization Policy</a> to validate all incoming requests.\nBy authoring the Authorization Policy to only accept paths corresponding to expected Rego package references, this attack can be fully mitigated.</p>\n<p>The HTTP path in a Data API request is of the format <code>/v1/data/{path:.+}</code> (<code>/v0/data/{path:.+}</code>, for the v0 Data API), where <code>data/{path:.+}</code> directly corresponds to a reference to a virtual document, and a prefix of <code>{path:.+}</code> corresponds to a Rego <code>package</code> declaration. \nE.g. the HTTP path <code>v1/data/do/re/mi</code> corresponds to the data reference <code>data.do.re.mi</code>, where <code>do.re</code> is the package and <code>mi</code> is the rule in the following Rego module:</p>\n<pre><code class=\"language-rego\">package do.re\n\nmi if {\n    ...\n}\n</code></pre>\n<p>Unless otherwise <a href=\"https://www.openpolicyagent.org/docs/latest/configuration/#miscellaneous\">configured</a>, OPA will use the rule at <code>data.system.authz.allow</code> as Authorization Policy. Authorization is enabled by starting OPA with the <code>--authorization=basic</code> flag, and the Authorization policy must be made available to the OPA runtime either through a bundle (via the <code>--bundle</code> flag or through <a href=\"https://www.openpolicyagent.org/docs/latest/management-discovery/\">discovery</a>) or as an individual module via the command-line.</p>\n<p>A trivial Authorization Policy example:</p>\n<pre><code class=\"language-rego\">package system.authz\n\nallowed_paths := [\n    [\"v1\", \"data\", \"policy1\", \"allow\"],\n    [\"v1\", \"data\", \"policy2\", \"allow\"],\n    ...\n]\n\nallow if {\n    input.path in allowed_paths\n}\n</code></pre>\n<p><strong>Note:</strong> configuring an Authorization Policy in OPA isn't the only way to protect against malicious request paths. Path validation and sanitisation can also be performed by connecting clients and 3rd party intermediaries, such as API gateways, reverse proxies, etc.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/open-policy-agent/opa/security/advisories/GHSA-6m8w-jc87-6cr7\">https://github.com/open-policy-agent/opa/security/advisories/GHSA-6m8w-jc87-6cr7</a></li>\n<li><a href=\"https://github.com/open-policy-agent/opa/commit/ad2063247a14711882f18c387a511fc8094aa79c\">https://github.com/open-policy-agent/opa/commit/ad2063247a14711882f18c387a511fc8094aa79c</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-6m8w-jc87-6cr7\">https://github.com/advisories/GHSA-6m8w-jc87-6cr7</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-6m8w-jc87-6cr7",
            "title": "[github.com/open-policy-agent/opa/server] OPA server Data API HTTP path injection of Rego",
            "date_modified": "2025-05-01T17:03:00.000Z",
            "date_published": "2025-05-01T17:02:58.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-6m8w-jc87-6cr7"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>When run as a server, OPA exposes an HTTP<a href=\"https://www.openpolicyagent.org/docs/latest/rest-api/#data-api\"> Data API</a> for reading and writing documents. Requesting a virtual document through the Data API entails policy evaluation, where a Rego query containing a single data document <a href=\"https://www.openpolicyagent.org/docs/latest/policy-language/#references\">reference</a> is constructed from the requested path. This query is then used for policy evaluation.</p>\n<p>A HTTP request path can be crafted in a way that injects Rego code into the constructed query. The evaluation result cannot be made to return any other data than what is generated by the requested path, but this path can be misdirected, and the injected Rego code can be crafted to make the query succeed or fail; opening up for oracle attacks or, given the right circumstances, erroneous policy decision results. Furthermore, the injected code can be crafted to be computationally expensive, resulting in a Denial Of Service (DoS) attack.</p>\n<p><strong>Users are only impacted if all of the following apply:</strong></p>\n<ul>\n<li>OPA is deployed as a standalone server (rather than being used as a Go library)</li>\n<li>The OPA server is exposed outside of the local host in an untrusted environment.</li>\n<li>The configured <a href=\"https://www.openpolicyagent.org/docs/latest/security/#authentication-and-authorization\">authorization policy</a> does not do exact matching of the <code>input.path</code> attribute when deciding if the request should be allowed.</li>\n</ul>\n<p><strong>or, if all of the following apply:</strong></p>\n<ul>\n<li>OPA is deployed as a standalone server.</li>\n<li>The service connecting to OPA allows 3rd parties to insert unsanitised text into the path of the HTTP request to OPA’s Data API.</li>\n</ul>\n<p><strong>Note:</strong> With <strong>no</strong> Authorization Policy configured for restricting API access (the default configuration), the RESTful Data API provides access for managing Rego policies; and the RESTful Query API facilitates advanced queries. Full access to these APIs provides both simpler, and broader access than what the security issue describes here can facilitate. As such, OPA servers exposed to a network are <strong>not</strong> considered affected by the attack described here if they are knowingly not restricting access through an Authorization Policy.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Fixed in OPA v1.4.0.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<h4 id=\"dont-publicly-expose-opas-restful-apis\">Don’t publicly expose OPA’s RESTful APIs</h4>\n<p>Unless necessary for production reasons, network access to OPA’s RESTful APIs should be limited to <code>localhost</code> and/or trusted networks. \nSince OPA v1.0, unless otherwise configured, the server listener defaults to <code>localhost</code>.</p>\n<h4 id=\"enable-authentication-to-only-allow-access-to-trusted-clients\">Enable Authentication to Only Allow Access to Trusted Clients</h4>\n<p>A configured <a href=\"https://www.openpolicyagent.org/docs/latest/security/#authentication-and-authorization\">authentication</a> scheme is a requirement when OPA is exposed in an untrusted environment. While requiring authentication alone doesn’t mitigate this attack, it effectively reduces the scope from untrusted clients to trusted clients.</p>\n<h4 id=\"perform-path-validation-using-opas-authorization-policy-functionality\">Perform Path Validation Using OPA’s Authorization Policy Functionality</h4>\n<p>OPA can be configured to use an <a href=\"https://www.openpolicyagent.org/docs/latest/security/#authentication-and-authorization\">Authorization Policy</a> to validate all incoming requests.\nBy authoring the Authorization Policy to only accept paths corresponding to expected Rego package references, this attack can be fully mitigated.</p>\n<p>The HTTP path in a Data API request is of the format <code>/v1/data/{path:.+}</code> (<code>/v0/data/{path:.+}</code>, for the v0 Data API), where <code>data/{path:.+}</code> directly corresponds to a reference to a virtual document, and a prefix of <code>{path:.+}</code> corresponds to a Rego <code>package</code> declaration. \nE.g. the HTTP path <code>v1/data/do/re/mi</code> corresponds to the data reference <code>data.do.re.mi</code>, where <code>do.re</code> is the package and <code>mi</code> is the rule in the following Rego module:</p>\n<pre><code class=\"language-rego\">package do.re\n\nmi if {\n    ...\n}\n</code></pre>\n<p>Unless otherwise <a href=\"https://www.openpolicyagent.org/docs/latest/configuration/#miscellaneous\">configured</a>, OPA will use the rule at <code>data.system.authz.allow</code> as Authorization Policy. Authorization is enabled by starting OPA with the <code>--authorization=basic</code> flag, and the Authorization policy must be made available to the OPA runtime either through a bundle (via the <code>--bundle</code> flag or through <a href=\"https://www.openpolicyagent.org/docs/latest/management-discovery/\">discovery</a>) or as an individual module via the command-line.</p>\n<p>A trivial Authorization Policy example:</p>\n<pre><code class=\"language-rego\">package system.authz\n\nallowed_paths := [\n    [\"v1\", \"data\", \"policy1\", \"allow\"],\n    [\"v1\", \"data\", \"policy2\", \"allow\"],\n    ...\n]\n\nallow if {\n    input.path in allowed_paths\n}\n</code></pre>\n<p><strong>Note:</strong> configuring an Authorization Policy in OPA isn't the only way to protect against malicious request paths. Path validation and sanitisation can also be performed by connecting clients and 3rd party intermediaries, such as API gateways, reverse proxies, etc.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/open-policy-agent/opa/security/advisories/GHSA-6m8w-jc87-6cr7\">https://github.com/open-policy-agent/opa/security/advisories/GHSA-6m8w-jc87-6cr7</a></li>\n<li><a href=\"https://github.com/open-policy-agent/opa/commit/ad2063247a14711882f18c387a511fc8094aa79c\">https://github.com/open-policy-agent/opa/commit/ad2063247a14711882f18c387a511fc8094aa79c</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-6m8w-jc87-6cr7\">https://github.com/advisories/GHSA-6m8w-jc87-6cr7</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-6m8w-jc87-6cr7",
            "title": "[github.com/open-policy-agent/opa/v1/server] OPA server Data API HTTP path injection of Rego",
            "date_modified": "2025-05-01T17:03:00.000Z",
            "date_published": "2025-05-01T17:02:58.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-6m8w-jc87-6cr7"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>Overview\nOpenFGA v1.8.10 or previous (Helm chart &lt;= openfga-0.2.28, docker &lt;= v.1.8.10) are vulnerable to authorization bypass when certain Check and ListObject calls are executed.</p>\n<p>Am I Affected?\nIf you are using OpenFGA v1.8.10 or previous, specifically under the following conditions, you are affected by this authorization bypass vulnerability:</p>\n<ul>\n<li>Calling Check API or ListObjects with an <a href=\"https://openfga.dev/docs/concepts#what-is-an-authorization-model\">authorization model</a> that has tuple cycle.</li>\n<li><a href=\"https://github.com/openfga/openfga/blob/9b5974458b777707ed2a30ba6303699499e655ee/.config-schema.json#L528\">Check query cache</a> is enabled, and</li>\n<li>There are multiple check / list objects requests involving the tuple cycle within the check query TTL</li>\n</ul>\n<p>Fix\nUpgrade to v1.8.11. This upgrade is backwards compatible.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/openfga/openfga/security/advisories/GHSA-w222-m46c-mgh6\">https://github.com/openfga/openfga/security/advisories/GHSA-w222-m46c-mgh6</a></li>\n<li><a href=\"https://github.com/openfga/openfga/commit/244302e7a8b979d66cc1874a3899cdff7d47862f\">https://github.com/openfga/openfga/commit/244302e7a8b979d66cc1874a3899cdff7d47862f</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-46331\">https://nvd.nist.gov/vuln/detail/CVE-2025-46331</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-w222-m46c-mgh6\">https://github.com/advisories/GHSA-w222-m46c-mgh6</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-w222-m46c-mgh6",
            "title": "[github.com/openfga/openfga] OpenFGA Authorization Bypass",
            "date_modified": "2025-05-01T13:30:20.000Z",
            "date_published": "2025-04-30T16:43:33.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-w222-m46c-mgh6"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>This issue allows an attacker who has compromised either the Elastic service or the extender plugin to cause denial of service of the scheduler. This is a privilege escalation, because Volcano users may run their Elastic service and extender plugins in separate pods or nodes from the scheduler. In the Kubernetes security model, node isolation is a security boundary, and as such an attacker is able to cross that boundary in Volcano's case if they have compromised either the vulnerable services or the pod/node in which they are deployed.  The scheduler will become unavailable to other users and workloads in the cluster. The scheduler will either crash with an unrecoverable OOM panic or freeze while consuming excessive amounts of memory.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>No</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/volcano-sh/volcano/security/advisories/GHSA-hg79-fw4p-25p8\">https://github.com/volcano-sh/volcano/security/advisories/GHSA-hg79-fw4p-25p8</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/45a4347471a5254121d10afef04c6732095fa398\">https://github.com/volcano-sh/volcano/commit/45a4347471a5254121d10afef04c6732095fa398</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/7103c18de19821cd278f949fa24c13da350a8c5d\">https://github.com/volcano-sh/volcano/commit/7103c18de19821cd278f949fa24c13da350a8c5d</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/735842af59b9be0da5090677db7693c98a798b2a\">https://github.com/volcano-sh/volcano/commit/735842af59b9be0da5090677db7693c98a798b2a</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/7c0ea53fa3cfa7a05b5fba7a8af7bfe88adc41c3\">https://github.com/volcano-sh/volcano/commit/7c0ea53fa3cfa7a05b5fba7a8af7bfe88adc41c3</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/d687f75a11fa36f37b54e4b6ff8e49bc0a3ca6b4\">https://github.com/volcano-sh/volcano/commit/d687f75a11fa36f37b54e4b6ff8e49bc0a3ca6b4</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-32777\">https://nvd.nist.gov/vuln/detail/CVE-2025-32777</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.10.2\">https://github.com/volcano-sh/volcano/releases/tag/v1.10.2</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.11.0-network-topology-preview.3\">https://github.com/volcano-sh/volcano/releases/tag/v1.11.0-network-topology-preview.3</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.11.2\">https://github.com/volcano-sh/volcano/releases/tag/v1.11.2</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.12.0-alpha.2\">https://github.com/volcano-sh/volcano/releases/tag/v1.12.0-alpha.2</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.9.1\">https://github.com/volcano-sh/volcano/releases/tag/v1.9.1</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-hg79-fw4p-25p8\">https://github.com/advisories/GHSA-hg79-fw4p-25p8</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-hg79-fw4p-25p8",
            "title": "[volcano.sh/volcano] Volcano Scheduler Denial of Service via Unbounded Response from Elastic Service/extender Plugin",
            "date_modified": "2025-05-01T13:30:15.000Z",
            "date_published": "2025-04-30T16:40:03.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-hg79-fw4p-25p8"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>This issue allows an attacker who has compromised either the Elastic service or the extender plugin to cause denial of service of the scheduler. This is a privilege escalation, because Volcano users may run their Elastic service and extender plugins in separate pods or nodes from the scheduler. In the Kubernetes security model, node isolation is a security boundary, and as such an attacker is able to cross that boundary in Volcano's case if they have compromised either the vulnerable services or the pod/node in which they are deployed.  The scheduler will become unavailable to other users and workloads in the cluster. The scheduler will either crash with an unrecoverable OOM panic or freeze while consuming excessive amounts of memory.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>No</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/volcano-sh/volcano/security/advisories/GHSA-hg79-fw4p-25p8\">https://github.com/volcano-sh/volcano/security/advisories/GHSA-hg79-fw4p-25p8</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/45a4347471a5254121d10afef04c6732095fa398\">https://github.com/volcano-sh/volcano/commit/45a4347471a5254121d10afef04c6732095fa398</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/7103c18de19821cd278f949fa24c13da350a8c5d\">https://github.com/volcano-sh/volcano/commit/7103c18de19821cd278f949fa24c13da350a8c5d</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/735842af59b9be0da5090677db7693c98a798b2a\">https://github.com/volcano-sh/volcano/commit/735842af59b9be0da5090677db7693c98a798b2a</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/7c0ea53fa3cfa7a05b5fba7a8af7bfe88adc41c3\">https://github.com/volcano-sh/volcano/commit/7c0ea53fa3cfa7a05b5fba7a8af7bfe88adc41c3</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/d687f75a11fa36f37b54e4b6ff8e49bc0a3ca6b4\">https://github.com/volcano-sh/volcano/commit/d687f75a11fa36f37b54e4b6ff8e49bc0a3ca6b4</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-32777\">https://nvd.nist.gov/vuln/detail/CVE-2025-32777</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.10.2\">https://github.com/volcano-sh/volcano/releases/tag/v1.10.2</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.11.0-network-topology-preview.3\">https://github.com/volcano-sh/volcano/releases/tag/v1.11.0-network-topology-preview.3</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.11.2\">https://github.com/volcano-sh/volcano/releases/tag/v1.11.2</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.12.0-alpha.2\">https://github.com/volcano-sh/volcano/releases/tag/v1.12.0-alpha.2</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.9.1\">https://github.com/volcano-sh/volcano/releases/tag/v1.9.1</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-hg79-fw4p-25p8\">https://github.com/advisories/GHSA-hg79-fw4p-25p8</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-hg79-fw4p-25p8",
            "title": "[volcano.sh/volcano] Volcano Scheduler Denial of Service via Unbounded Response from Elastic Service/extender Plugin",
            "date_modified": "2025-05-01T13:30:15.000Z",
            "date_published": "2025-04-30T16:40:03.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-hg79-fw4p-25p8"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>This issue allows an attacker who has compromised either the Elastic service or the extender plugin to cause denial of service of the scheduler. This is a privilege escalation, because Volcano users may run their Elastic service and extender plugins in separate pods or nodes from the scheduler. In the Kubernetes security model, node isolation is a security boundary, and as such an attacker is able to cross that boundary in Volcano's case if they have compromised either the vulnerable services or the pod/node in which they are deployed.  The scheduler will become unavailable to other users and workloads in the cluster. The scheduler will either crash with an unrecoverable OOM panic or freeze while consuming excessive amounts of memory.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>No</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/volcano-sh/volcano/security/advisories/GHSA-hg79-fw4p-25p8\">https://github.com/volcano-sh/volcano/security/advisories/GHSA-hg79-fw4p-25p8</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/45a4347471a5254121d10afef04c6732095fa398\">https://github.com/volcano-sh/volcano/commit/45a4347471a5254121d10afef04c6732095fa398</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/7103c18de19821cd278f949fa24c13da350a8c5d\">https://github.com/volcano-sh/volcano/commit/7103c18de19821cd278f949fa24c13da350a8c5d</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/735842af59b9be0da5090677db7693c98a798b2a\">https://github.com/volcano-sh/volcano/commit/735842af59b9be0da5090677db7693c98a798b2a</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/7c0ea53fa3cfa7a05b5fba7a8af7bfe88adc41c3\">https://github.com/volcano-sh/volcano/commit/7c0ea53fa3cfa7a05b5fba7a8af7bfe88adc41c3</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/d687f75a11fa36f37b54e4b6ff8e49bc0a3ca6b4\">https://github.com/volcano-sh/volcano/commit/d687f75a11fa36f37b54e4b6ff8e49bc0a3ca6b4</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-32777\">https://nvd.nist.gov/vuln/detail/CVE-2025-32777</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.10.2\">https://github.com/volcano-sh/volcano/releases/tag/v1.10.2</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.11.0-network-topology-preview.3\">https://github.com/volcano-sh/volcano/releases/tag/v1.11.0-network-topology-preview.3</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.11.2\">https://github.com/volcano-sh/volcano/releases/tag/v1.11.2</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.12.0-alpha.2\">https://github.com/volcano-sh/volcano/releases/tag/v1.12.0-alpha.2</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.9.1\">https://github.com/volcano-sh/volcano/releases/tag/v1.9.1</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-hg79-fw4p-25p8\">https://github.com/advisories/GHSA-hg79-fw4p-25p8</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-hg79-fw4p-25p8",
            "title": "[volcano.sh/volcano] Volcano Scheduler Denial of Service via Unbounded Response from Elastic Service/extender Plugin",
            "date_modified": "2025-05-01T13:30:15.000Z",
            "date_published": "2025-04-30T16:40:03.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-hg79-fw4p-25p8"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>This issue allows an attacker who has compromised either the Elastic service or the extender plugin to cause denial of service of the scheduler. This is a privilege escalation, because Volcano users may run their Elastic service and extender plugins in separate pods or nodes from the scheduler. In the Kubernetes security model, node isolation is a security boundary, and as such an attacker is able to cross that boundary in Volcano's case if they have compromised either the vulnerable services or the pod/node in which they are deployed.  The scheduler will become unavailable to other users and workloads in the cluster. The scheduler will either crash with an unrecoverable OOM panic or freeze while consuming excessive amounts of memory.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>No</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/volcano-sh/volcano/security/advisories/GHSA-hg79-fw4p-25p8\">https://github.com/volcano-sh/volcano/security/advisories/GHSA-hg79-fw4p-25p8</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/45a4347471a5254121d10afef04c6732095fa398\">https://github.com/volcano-sh/volcano/commit/45a4347471a5254121d10afef04c6732095fa398</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/7103c18de19821cd278f949fa24c13da350a8c5d\">https://github.com/volcano-sh/volcano/commit/7103c18de19821cd278f949fa24c13da350a8c5d</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/735842af59b9be0da5090677db7693c98a798b2a\">https://github.com/volcano-sh/volcano/commit/735842af59b9be0da5090677db7693c98a798b2a</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/7c0ea53fa3cfa7a05b5fba7a8af7bfe88adc41c3\">https://github.com/volcano-sh/volcano/commit/7c0ea53fa3cfa7a05b5fba7a8af7bfe88adc41c3</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/d687f75a11fa36f37b54e4b6ff8e49bc0a3ca6b4\">https://github.com/volcano-sh/volcano/commit/d687f75a11fa36f37b54e4b6ff8e49bc0a3ca6b4</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-32777\">https://nvd.nist.gov/vuln/detail/CVE-2025-32777</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.10.2\">https://github.com/volcano-sh/volcano/releases/tag/v1.10.2</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.11.0-network-topology-preview.3\">https://github.com/volcano-sh/volcano/releases/tag/v1.11.0-network-topology-preview.3</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.11.2\">https://github.com/volcano-sh/volcano/releases/tag/v1.11.2</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.12.0-alpha.2\">https://github.com/volcano-sh/volcano/releases/tag/v1.12.0-alpha.2</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.9.1\">https://github.com/volcano-sh/volcano/releases/tag/v1.9.1</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-hg79-fw4p-25p8\">https://github.com/advisories/GHSA-hg79-fw4p-25p8</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-hg79-fw4p-25p8",
            "title": "[volcano.sh/volcano] Volcano Scheduler Denial of Service via Unbounded Response from Elastic Service/extender Plugin",
            "date_modified": "2025-05-01T13:30:15.000Z",
            "date_published": "2025-04-30T16:40:03.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-hg79-fw4p-25p8"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>This issue allows an attacker who has compromised either the Elastic service or the extender plugin to cause denial of service of the scheduler. This is a privilege escalation, because Volcano users may run their Elastic service and extender plugins in separate pods or nodes from the scheduler. In the Kubernetes security model, node isolation is a security boundary, and as such an attacker is able to cross that boundary in Volcano's case if they have compromised either the vulnerable services or the pod/node in which they are deployed.  The scheduler will become unavailable to other users and workloads in the cluster. The scheduler will either crash with an unrecoverable OOM panic or freeze while consuming excessive amounts of memory.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>No</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/volcano-sh/volcano/security/advisories/GHSA-hg79-fw4p-25p8\">https://github.com/volcano-sh/volcano/security/advisories/GHSA-hg79-fw4p-25p8</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/45a4347471a5254121d10afef04c6732095fa398\">https://github.com/volcano-sh/volcano/commit/45a4347471a5254121d10afef04c6732095fa398</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/7103c18de19821cd278f949fa24c13da350a8c5d\">https://github.com/volcano-sh/volcano/commit/7103c18de19821cd278f949fa24c13da350a8c5d</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/735842af59b9be0da5090677db7693c98a798b2a\">https://github.com/volcano-sh/volcano/commit/735842af59b9be0da5090677db7693c98a798b2a</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/7c0ea53fa3cfa7a05b5fba7a8af7bfe88adc41c3\">https://github.com/volcano-sh/volcano/commit/7c0ea53fa3cfa7a05b5fba7a8af7bfe88adc41c3</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/commit/d687f75a11fa36f37b54e4b6ff8e49bc0a3ca6b4\">https://github.com/volcano-sh/volcano/commit/d687f75a11fa36f37b54e4b6ff8e49bc0a3ca6b4</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-32777\">https://nvd.nist.gov/vuln/detail/CVE-2025-32777</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.10.2\">https://github.com/volcano-sh/volcano/releases/tag/v1.10.2</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.11.0-network-topology-preview.3\">https://github.com/volcano-sh/volcano/releases/tag/v1.11.0-network-topology-preview.3</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.11.2\">https://github.com/volcano-sh/volcano/releases/tag/v1.11.2</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.12.0-alpha.2\">https://github.com/volcano-sh/volcano/releases/tag/v1.12.0-alpha.2</a></li>\n<li><a href=\"https://github.com/volcano-sh/volcano/releases/tag/v1.9.1\">https://github.com/volcano-sh/volcano/releases/tag/v1.9.1</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-hg79-fw4p-25p8\">https://github.com/advisories/GHSA-hg79-fw4p-25p8</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-hg79-fw4p-25p8",
            "title": "[volcano.sh/volcano] Volcano Scheduler Denial of Service via Unbounded Response from Elastic Service/extender Plugin",
            "date_modified": "2025-05-01T13:30:15.000Z",
            "date_published": "2025-04-30T16:40:03.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-hg79-fw4p-25p8"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"summary\">Summary</h3>\n<p>Due to a missing error propagation in function <code>GetNamespaceSelectorsFromNamespaceLister</code> in <code>pkg/utils/engine/labels.go</code> it may happen that policy rules using namespace selector(s) in their <code>match</code> statements are mistakenly not applied during admission review request processing. As a consequence, security-critical mutations and validations are bypassed, potentially allowing attackers with K8s API access to perform malicious operations.</p>\n<h3 id=\"details\">Details</h3>\n<p>As a policy engine Kyverno is a critical component ensuring the security of Kubernetes clusters by apply security-relevant policy rules in the Kubernetes admission control process.</p>\n<p>We encountered a case where Kyverno did not apply policy rules which should have been applied.  This happened in both the mutation and the validation phase of admission control.  Effectively Kyverno handled the admission review requests as\nif those policy rules did not exist.  Consequently, the Kube API request was accepted without applying security-relevant patches and validations.</p>\n<p>As the root cause we identified a missing error propagation in function <code>GetNamespaceSelectorsFromNamespaceLister</code> in <code>pkg/utils/engine/labels.go</code> (<a href=\"https://github.com/kyverno/kyverno/blob/a96b1a4794b4d25cb0c6d72c05fc6355e95cf65c/pkg/utils/engine/labels.go#L10\">src</a>).</p>\n<p>All affected policy rules use a namespace selector in their match resource filters like this:</p>\n<pre><code class=\"language-yaml\">match:\n  all:\n  - resources:\n      namespaceSelector:\n        matchExpressions:\n        - key: label1\n          operator: Exists\n</code></pre>\n<p>Such specification intents to apply rules only to resource objects which reside in a namespace whose labels match the given label expressions.</p>\n<p>When Kyverno handles an admission webhook, function <code>GetNamespaceSelectorsFromNamespaceLister</code> in package\n<code>github.com/kyverno/kyverno/pkg/utils/engine</code> (<a href=\"https://github.com/kyverno/kyverno/blob/a96b1a4794b4d25cb0c6d72c05fc6355e95cf65c/pkg/utils/engine/labels.go#L10\">src</a>) is called to retrieve the labels of the request object's namespace.  This function gets the namespace object from a <code>\"k8s.io/client-go/listers/core/v1\".NamespaceLister</code>.  In case the\nnamespace lister returns an error, <code>GetNamespaceSelectorsFromNamespaceLister</code> does NOT propagate this error to its caller, but returns an empty label map, which is equivalent to a namespace without any labels.</p>\n<p>The returned label map is later used to select matching policy rules.  If a rule has a resource filter with namespace selector, it will be mistakenly excluded or included.</p>\n<p>The namespace lister fails to return the namespace object if the underlying <code>SharedIndexInformer</code> has not (yet) updated its cache.  Those updates happen based on watch events from the Kube API Server, which does not guarantee any maximum delivery time.  If the Kube API Server handling the watch is under high load or otherwise impaired (e.g. requests to etcd take longer due to pending leader election in HA setup) then informer cache updates can be delayed significantly.  However, we did not find a way to reliably reproduce such condition.</p>\n<p>To bypass Kyverno policies, an attacker may try to exploit the described misbehavior by:</p>\n<ul>\n<li><p>putting the Kube API Server under load before sending requests that Kyverno policies should be bypassed for.</p>\n</li>\n<li><p>sending many request with a high rate to Kube API Server.</p>\n</li>\n</ul>\n<p>We did not try any of such attack vectors and therefore cannot prove their effectiveness.</p>\n<p>In our scenario the Kyverno policies apply to pods in \"sandbox\" namespaces identified as such by certain labels.  Those single-use namespaces and the pods therein are frequently created (and removed) by other controllers.  Therefore, Kyverno often receives admission webhooks for objects whose namespace has been created shortly before.</p>\n<h4 id=\"correction-proposal\">Correction Proposal</h4>\n<p>Function <code>GetNamespaceSelectorsFromNamespaceLister</code> in package <code>github.com/kyverno/kyverno/pkg/utils/engine</code> (<a href=\"https://github.com/kyverno/kyverno/blob/a96b1a4794b4d25cb0c6d72c05fc6355e95cf65c/pkg/utils/engine/labels.go#L10\">src</a>) should return an error instead of an empty label map in case it could not get the namespace object from the namespace lister.  This error will then cause admission webhook processing to fail, which lets Kubernetes fail the Kube API request if the policy's failure policy is <code>Fail</code> (a must for security-relevant policies).</p>\n<p>In addition, function <code>GetNamespaceSelectorsFromNamespaceLister</code> could retry (with deadline) to get the namespace object from the namespace lister in case of a NotFound error.  But as admission webhook processing time should be kept as short as possible, this might not be a good idea.</p>\n<p>Another option would be to perform a GET request for the namespace as a fallback in case the namespace lister returns a NotFound error.</p>\n<h3 id=\"poc\">PoC</h3>\n<p>We did not find a way to reliably reproduce such case.</p>\n<h3 id=\"impact\">Impact</h3>\n<p>Administrators attempting to enforce cluster security through Kyverno policies, but that allow less privileged users or service accounts to create/update/delete resources.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/kyverno/kyverno/security/advisories/GHSA-jrr2-x33p-6hvc\">https://github.com/kyverno/kyverno/security/advisories/GHSA-jrr2-x33p-6hvc</a></li>\n<li><a href=\"https://github.com/kyverno/kyverno/commit/3ff923b7756e1681daf73849954bd88516589194\">https://github.com/kyverno/kyverno/commit/3ff923b7756e1681daf73849954bd88516589194</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-46342\">https://nvd.nist.gov/vuln/detail/CVE-2025-46342</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-jrr2-x33p-6hvc\">https://github.com/advisories/GHSA-jrr2-x33p-6hvc</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-jrr2-x33p-6hvc",
            "title": "[github.com/kyverno/kyverno] Kyverno vulnerable to bypass of policy rules that use namespace selectors in match statements",
            "date_modified": "2025-04-30T17:29:39.000Z",
            "date_published": "2025-04-29T16:39:33.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-jrr2-x33p-6hvc"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"summary\">Summary</h3>\n<p>Due to a missing error propagation in function <code>GetNamespaceSelectorsFromNamespaceLister</code> in <code>pkg/utils/engine/labels.go</code> it may happen that policy rules using namespace selector(s) in their <code>match</code> statements are mistakenly not applied during admission review request processing. As a consequence, security-critical mutations and validations are bypassed, potentially allowing attackers with K8s API access to perform malicious operations.</p>\n<h3 id=\"details\">Details</h3>\n<p>As a policy engine Kyverno is a critical component ensuring the security of Kubernetes clusters by apply security-relevant policy rules in the Kubernetes admission control process.</p>\n<p>We encountered a case where Kyverno did not apply policy rules which should have been applied.  This happened in both the mutation and the validation phase of admission control.  Effectively Kyverno handled the admission review requests as\nif those policy rules did not exist.  Consequently, the Kube API request was accepted without applying security-relevant patches and validations.</p>\n<p>As the root cause we identified a missing error propagation in function <code>GetNamespaceSelectorsFromNamespaceLister</code> in <code>pkg/utils/engine/labels.go</code> (<a href=\"https://github.com/kyverno/kyverno/blob/a96b1a4794b4d25cb0c6d72c05fc6355e95cf65c/pkg/utils/engine/labels.go#L10\">src</a>).</p>\n<p>All affected policy rules use a namespace selector in their match resource filters like this:</p>\n<pre><code class=\"language-yaml\">match:\n  all:\n  - resources:\n      namespaceSelector:\n        matchExpressions:\n        - key: label1\n          operator: Exists\n</code></pre>\n<p>Such specification intents to apply rules only to resource objects which reside in a namespace whose labels match the given label expressions.</p>\n<p>When Kyverno handles an admission webhook, function <code>GetNamespaceSelectorsFromNamespaceLister</code> in package\n<code>github.com/kyverno/kyverno/pkg/utils/engine</code> (<a href=\"https://github.com/kyverno/kyverno/blob/a96b1a4794b4d25cb0c6d72c05fc6355e95cf65c/pkg/utils/engine/labels.go#L10\">src</a>) is called to retrieve the labels of the request object's namespace.  This function gets the namespace object from a <code>\"k8s.io/client-go/listers/core/v1\".NamespaceLister</code>.  In case the\nnamespace lister returns an error, <code>GetNamespaceSelectorsFromNamespaceLister</code> does NOT propagate this error to its caller, but returns an empty label map, which is equivalent to a namespace without any labels.</p>\n<p>The returned label map is later used to select matching policy rules.  If a rule has a resource filter with namespace selector, it will be mistakenly excluded or included.</p>\n<p>The namespace lister fails to return the namespace object if the underlying <code>SharedIndexInformer</code> has not (yet) updated its cache.  Those updates happen based on watch events from the Kube API Server, which does not guarantee any maximum delivery time.  If the Kube API Server handling the watch is under high load or otherwise impaired (e.g. requests to etcd take longer due to pending leader election in HA setup) then informer cache updates can be delayed significantly.  However, we did not find a way to reliably reproduce such condition.</p>\n<p>To bypass Kyverno policies, an attacker may try to exploit the described misbehavior by:</p>\n<ul>\n<li><p>putting the Kube API Server under load before sending requests that Kyverno policies should be bypassed for.</p>\n</li>\n<li><p>sending many request with a high rate to Kube API Server.</p>\n</li>\n</ul>\n<p>We did not try any of such attack vectors and therefore cannot prove their effectiveness.</p>\n<p>In our scenario the Kyverno policies apply to pods in \"sandbox\" namespaces identified as such by certain labels.  Those single-use namespaces and the pods therein are frequently created (and removed) by other controllers.  Therefore, Kyverno often receives admission webhooks for objects whose namespace has been created shortly before.</p>\n<h4 id=\"correction-proposal\">Correction Proposal</h4>\n<p>Function <code>GetNamespaceSelectorsFromNamespaceLister</code> in package <code>github.com/kyverno/kyverno/pkg/utils/engine</code> (<a href=\"https://github.com/kyverno/kyverno/blob/a96b1a4794b4d25cb0c6d72c05fc6355e95cf65c/pkg/utils/engine/labels.go#L10\">src</a>) should return an error instead of an empty label map in case it could not get the namespace object from the namespace lister.  This error will then cause admission webhook processing to fail, which lets Kubernetes fail the Kube API request if the policy's failure policy is <code>Fail</code> (a must for security-relevant policies).</p>\n<p>In addition, function <code>GetNamespaceSelectorsFromNamespaceLister</code> could retry (with deadline) to get the namespace object from the namespace lister in case of a NotFound error.  But as admission webhook processing time should be kept as short as possible, this might not be a good idea.</p>\n<p>Another option would be to perform a GET request for the namespace as a fallback in case the namespace lister returns a NotFound error.</p>\n<h3 id=\"poc\">PoC</h3>\n<p>We did not find a way to reliably reproduce such case.</p>\n<h3 id=\"impact\">Impact</h3>\n<p>Administrators attempting to enforce cluster security through Kyverno policies, but that allow less privileged users or service accounts to create/update/delete resources.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/kyverno/kyverno/security/advisories/GHSA-jrr2-x33p-6hvc\">https://github.com/kyverno/kyverno/security/advisories/GHSA-jrr2-x33p-6hvc</a></li>\n<li><a href=\"https://github.com/kyverno/kyverno/commit/3ff923b7756e1681daf73849954bd88516589194\">https://github.com/kyverno/kyverno/commit/3ff923b7756e1681daf73849954bd88516589194</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-46342\">https://nvd.nist.gov/vuln/detail/CVE-2025-46342</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-jrr2-x33p-6hvc\">https://github.com/advisories/GHSA-jrr2-x33p-6hvc</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-jrr2-x33p-6hvc",
            "title": "[github.com/kyverno/kyverno] Kyverno vulnerable to bypass of policy rules that use namespace selectors in match statements",
            "date_modified": "2025-04-30T17:29:39.000Z",
            "date_published": "2025-04-29T16:39:33.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-jrr2-x33p-6hvc"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h1 id=\"issue\">Issue</h1>\n<p>Snowflake discovered and remediated a vulnerability in the Go Snowflake Driver (“Driver”). When using the Easy Logging feature on Linux and macOS, the Driver didn’t correctly verify the permissions of the logging configuration file, potentially allowing an attacker with local access to overwrite the configuration and gain control over logging level and output location.</p>\n<p>This vulnerability affects Driver versions from 1.7.0 up to, but not including, 1.13.3. Snowflake fixed the issue in version 1.13.3.</p>\n<h1 id=\"vulnerability-details\">Vulnerability Details</h1>\n<p>When using the Easy Logging feature on Linux and macOS, the Driver reads logging configuration from a user-provided file. On Linux and macOS the Driver verifies that the configuration file can be written to only by its owner. That check was vulnerable to a Time-of-Check to Time-of-Use (TOCTOU) race condition and failed to verify that the file owner matches the user running the Driver. This could allow a local attacker with write access to the configuration file or the directory containing it to overwrite the configuration and gain control over logging level and output location.</p>\n<h1 id=\"solution\">Solution</h1>\n<p>Snowflake released version 1.13.3 of the Go Snowflake Driver, which fixes this issue. We recommend users upgrade to version 1.13.3.</p>\n<h1 id=\"additional-information\">Additional Information</h1>\n<p>If you discover a security vulnerability in one of our products or websites, please report the issue to Snowflake through our Vulnerability Disclosure Program hosted at HackerOne. For more information, please see our <a href=\"https://hackerone.com/snowflake?type=team\">Vulnerability Disclosure Policy</a>.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/snowflakedb/gosnowflake/security/advisories/GHSA-6jgm-j7h2-2fqg\">https://github.com/snowflakedb/gosnowflake/security/advisories/GHSA-6jgm-j7h2-2fqg</a></li>\n<li><a href=\"https://github.com/snowflakedb/gosnowflake/commit/ba94a4800e23621eff558ef18ce4b96ec5489ff0\">https://github.com/snowflakedb/gosnowflake/commit/ba94a4800e23621eff558ef18ce4b96ec5489ff0</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-46327\">https://nvd.nist.gov/vuln/detail/CVE-2025-46327</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-6jgm-j7h2-2fqg\">https://github.com/advisories/GHSA-6jgm-j7h2-2fqg</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-6jgm-j7h2-2fqg",
            "title": "[github.com/snowflakedb/gosnowflake] Go Snowflake Driver has race condition when checking access to Easy Logging configuration file",
            "date_modified": "2025-04-29T13:10:42.000Z",
            "date_published": "2025-04-28T20:27:29.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-6jgm-j7h2-2fqg"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>A vulnerability has been identified in Steve where by default it was using an insecure option that did not validate the certificate presented by the remote server while performing a TLS connection. This could allow the execution of a man-in-the-middle (MitM) attack against services using Steve.</p>\n<p>For example, Rancher relies on Steve as a dependency for its user interface (UI) to proxy requests to Kubernetes clusters. Users who have the permission to create a service in Rancher’s local cluster can take over Rancher’s UI and display their own UI to gather sensitive information. This is only possible when the setting <code>ui-offline-preferred</code> is manually set to <code>remote</code> (by default Rancher sets it to <code>dynamic</code>). This enables further attacks such as cross-site scripting (XSS), or tampering the UI to collect passwords from other users etc.</p>\n<p>Please consult the associated  <a href=\"https://attack.mitre.org/techniques/T1557/\">MITRE ATT&amp;CK - Technique - Adversary-in-the-Middle</a> for further information about this category of attack.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Patched versions of Steve include releases <code>v0.2.1</code>, <code>v0.3.3</code>, <code>v0.4.4</code> and <code>v0.5.13</code>.</p>\n<p>This vulnerability is addressed by changing Steve to always verify a server’s certificate based on Go’s TLS settings.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>If you can't upgrade to a fixed version, please make sure that you are only using Steve to connect to trusted servers.</p>\n<h3 id=\"references\">References</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li>Reach out to the <a href=\"https://github.com/rancher/rancher/security/policy\">SUSE Rancher Security team</a> for security related inquiries.</li>\n<li>Open an issue in the <a href=\"https://github.com/rancher/rancher/issues/new/choose\">Rancher</a> repository.</li>\n<li>Verify with our <a href=\"https://www.suse.com/suse-rancher/support-matrix/all-supported-versions/\">support matrix</a> and <a href=\"https://www.suse.com/lifecycle/\">product support lifecycle</a>.</li>\n</ul>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/rancher/steve/security/advisories/GHSA-95fc-g4gj-mqmx\">https://github.com/rancher/steve/security/advisories/GHSA-95fc-g4gj-mqmx</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-95fc-g4gj-mqmx\">https://github.com/advisories/GHSA-95fc-g4gj-mqmx</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-95fc-g4gj-mqmx",
            "title": "[github.com/rancher/steve] Steve doesn’t verify a server’s certificate and is susceptible to man-in-the-middle (MitM) attacks",
            "date_modified": "2025-04-25T15:12:45.000Z",
            "date_published": "2025-04-25T15:12:44.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-95fc-g4gj-mqmx"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>A vulnerability has been identified in Steve where by default it was using an insecure option that did not validate the certificate presented by the remote server while performing a TLS connection. This could allow the execution of a man-in-the-middle (MitM) attack against services using Steve.</p>\n<p>For example, Rancher relies on Steve as a dependency for its user interface (UI) to proxy requests to Kubernetes clusters. Users who have the permission to create a service in Rancher’s local cluster can take over Rancher’s UI and display their own UI to gather sensitive information. This is only possible when the setting <code>ui-offline-preferred</code> is manually set to <code>remote</code> (by default Rancher sets it to <code>dynamic</code>). This enables further attacks such as cross-site scripting (XSS), or tampering the UI to collect passwords from other users etc.</p>\n<p>Please consult the associated  <a href=\"https://attack.mitre.org/techniques/T1557/\">MITRE ATT&amp;CK - Technique - Adversary-in-the-Middle</a> for further information about this category of attack.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Patched versions of Steve include releases <code>v0.2.1</code>, <code>v0.3.3</code>, <code>v0.4.4</code> and <code>v0.5.13</code>.</p>\n<p>This vulnerability is addressed by changing Steve to always verify a server’s certificate based on Go’s TLS settings.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>If you can't upgrade to a fixed version, please make sure that you are only using Steve to connect to trusted servers.</p>\n<h3 id=\"references\">References</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li>Reach out to the <a href=\"https://github.com/rancher/rancher/security/policy\">SUSE Rancher Security team</a> for security related inquiries.</li>\n<li>Open an issue in the <a href=\"https://github.com/rancher/rancher/issues/new/choose\">Rancher</a> repository.</li>\n<li>Verify with our <a href=\"https://www.suse.com/suse-rancher/support-matrix/all-supported-versions/\">support matrix</a> and <a href=\"https://www.suse.com/lifecycle/\">product support lifecycle</a>.</li>\n</ul>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/rancher/steve/security/advisories/GHSA-95fc-g4gj-mqmx\">https://github.com/rancher/steve/security/advisories/GHSA-95fc-g4gj-mqmx</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-95fc-g4gj-mqmx\">https://github.com/advisories/GHSA-95fc-g4gj-mqmx</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-95fc-g4gj-mqmx",
            "title": "[github.com/rancher/steve] Steve doesn’t verify a server’s certificate and is susceptible to man-in-the-middle (MitM) attacks",
            "date_modified": "2025-04-25T15:12:45.000Z",
            "date_published": "2025-04-25T15:12:44.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-95fc-g4gj-mqmx"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>A vulnerability has been identified in Steve where by default it was using an insecure option that did not validate the certificate presented by the remote server while performing a TLS connection. This could allow the execution of a man-in-the-middle (MitM) attack against services using Steve.</p>\n<p>For example, Rancher relies on Steve as a dependency for its user interface (UI) to proxy requests to Kubernetes clusters. Users who have the permission to create a service in Rancher’s local cluster can take over Rancher’s UI and display their own UI to gather sensitive information. This is only possible when the setting <code>ui-offline-preferred</code> is manually set to <code>remote</code> (by default Rancher sets it to <code>dynamic</code>). This enables further attacks such as cross-site scripting (XSS), or tampering the UI to collect passwords from other users etc.</p>\n<p>Please consult the associated  <a href=\"https://attack.mitre.org/techniques/T1557/\">MITRE ATT&amp;CK - Technique - Adversary-in-the-Middle</a> for further information about this category of attack.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Patched versions of Steve include releases <code>v0.2.1</code>, <code>v0.3.3</code>, <code>v0.4.4</code> and <code>v0.5.13</code>.</p>\n<p>This vulnerability is addressed by changing Steve to always verify a server’s certificate based on Go’s TLS settings.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>If you can't upgrade to a fixed version, please make sure that you are only using Steve to connect to trusted servers.</p>\n<h3 id=\"references\">References</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li>Reach out to the <a href=\"https://github.com/rancher/rancher/security/policy\">SUSE Rancher Security team</a> for security related inquiries.</li>\n<li>Open an issue in the <a href=\"https://github.com/rancher/rancher/issues/new/choose\">Rancher</a> repository.</li>\n<li>Verify with our <a href=\"https://www.suse.com/suse-rancher/support-matrix/all-supported-versions/\">support matrix</a> and <a href=\"https://www.suse.com/lifecycle/\">product support lifecycle</a>.</li>\n</ul>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/rancher/steve/security/advisories/GHSA-95fc-g4gj-mqmx\">https://github.com/rancher/steve/security/advisories/GHSA-95fc-g4gj-mqmx</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-95fc-g4gj-mqmx\">https://github.com/advisories/GHSA-95fc-g4gj-mqmx</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-95fc-g4gj-mqmx",
            "title": "[github.com/rancher/stev] Steve doesn’t verify a server’s certificate and is susceptible to man-in-the-middle (MitM) attacks",
            "date_modified": "2025-04-25T15:12:45.000Z",
            "date_published": "2025-04-25T15:12:44.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-95fc-g4gj-mqmx"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>A vulnerability has been identified in Steve where by default it was using an insecure option that did not validate the certificate presented by the remote server while performing a TLS connection. This could allow the execution of a man-in-the-middle (MitM) attack against services using Steve.</p>\n<p>For example, Rancher relies on Steve as a dependency for its user interface (UI) to proxy requests to Kubernetes clusters. Users who have the permission to create a service in Rancher’s local cluster can take over Rancher’s UI and display their own UI to gather sensitive information. This is only possible when the setting <code>ui-offline-preferred</code> is manually set to <code>remote</code> (by default Rancher sets it to <code>dynamic</code>). This enables further attacks such as cross-site scripting (XSS), or tampering the UI to collect passwords from other users etc.</p>\n<p>Please consult the associated  <a href=\"https://attack.mitre.org/techniques/T1557/\">MITRE ATT&amp;CK - Technique - Adversary-in-the-Middle</a> for further information about this category of attack.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Patched versions of Steve include releases <code>v0.2.1</code>, <code>v0.3.3</code>, <code>v0.4.4</code> and <code>v0.5.13</code>.</p>\n<p>This vulnerability is addressed by changing Steve to always verify a server’s certificate based on Go’s TLS settings.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>If you can't upgrade to a fixed version, please make sure that you are only using Steve to connect to trusted servers.</p>\n<h3 id=\"references\">References</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li>Reach out to the <a href=\"https://github.com/rancher/rancher/security/policy\">SUSE Rancher Security team</a> for security related inquiries.</li>\n<li>Open an issue in the <a href=\"https://github.com/rancher/rancher/issues/new/choose\">Rancher</a> repository.</li>\n<li>Verify with our <a href=\"https://www.suse.com/suse-rancher/support-matrix/all-supported-versions/\">support matrix</a> and <a href=\"https://www.suse.com/lifecycle/\">product support lifecycle</a>.</li>\n</ul>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/rancher/steve/security/advisories/GHSA-95fc-g4gj-mqmx\">https://github.com/rancher/steve/security/advisories/GHSA-95fc-g4gj-mqmx</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-95fc-g4gj-mqmx\">https://github.com/advisories/GHSA-95fc-g4gj-mqmx</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-95fc-g4gj-mqmx",
            "title": "[github.com/rancher/steve] Steve doesn’t verify a server’s certificate and is susceptible to man-in-the-middle (MitM) attacks",
            "date_modified": "2025-04-25T15:12:45.000Z",
            "date_published": "2025-04-25T15:12:44.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-95fc-g4gj-mqmx"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>A vulnerability has been identified within Fleet where, by default, Fleet will automatically trust a remote server’s certificate when connecting through SSH if the certificate isn’t set in the <code>known_hosts</code> file. This could allow the execution of a man-in-the-middle (MitM) attack against Fleet. In case the server that is being connected to has a trusted entry in the known_hosts file, then Fleet will correctly check the authenticity of the presented certificate. </p>\n<p>Please consult the associated  <a href=\"https://attack.mitre.org/techniques/T1557/\">MITRE ATT&amp;CK - Technique - Adversary-in-the-Middle</a> for further information about this category of attack.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Patched versions include releases <code>v0.10.12</code>, <code>v0.11.7</code> and <code>v0.12.2</code>.</p>\n<p>The fix involves some key areas with the following changes:</p>\n<ul>\n<li><p>Git latest commit fetcher sources <code>known_hosts</code> entries from the following locations, in decreasing order of priority:</p>\n<ol>\n<li>Secret referenced in a <code>GitRepo</code>’s <code>clientSecretName</code> field;</li>\n<li>If no secret is referenced, in a <code>gitcredential</code> secret located in the <code>GitRepo</code>’s namespace;</li>\n<li>If that secret does not exist, in a (new) <code>known-hosts</code> config map installed by Fleet, populated statically with public entries shared by a few git providers: Github, Gitlab, Bitbucket, Azure DevOps;</li>\n</ol>\n</li>\n<li><p>Git cloner: same as above.</p>\n</li>\n<li><p><code>fleet apply</code> command: same as above. The command reads entries from a <code>FLEET_KNOWN_HOSTS</code> environment variable. That command is typically run within a container inside a job pod created by Fleet to update bundles from a new commit. However, users may also decide to run it locally, perhaps even with multiple concurrent executions of the command on the same machine. To cater for this, <code>fleet apply</code> writes the contents of <code>FLEET_KNOWN_HOSTS</code>, if any, to a temporary file with a random name, and deletes that file once bundles have been created. This reduces the risk of conflicts between concurrent runs.\nThis happens regardless of the git repository URL (SSH or not), since a repository may reference artifacts to be retrieved using SSH anyway.</p>\n</li>\n</ul>\n<p><strong>Note about sourcing <code>known_hosts</code> entries:</strong> if entries are found in a supported source, whatever that source may be, then those entries will be used. For instance, if wrong entries, or an incomplete set of entries (e.g. only BitBucket entries for a <code>GitRepo</code> pointing to Github) are found in a secret referenced in a <code>GitRepo</code>’s <code>clientSecretName</code> field, they will still be used. This will lead to errors if strict host key checks are enabled, even if matching, correct entries are found in another source with lower priority, such as the <code>known-hosts</code> config map. Fleet will not use one source to complement the other.</p>\n<p><strong>Note: Fleet v0.9 release line does not have the fix for this CVE. The fix for v0.9 was considered too complex and with the risk of introducing instabilities right before this version goes into end-of-life (EOL), as documented in <a href=\"https://www.suse.com/lifecycle/#suse-rancher-prime\">SUSE’s Product Support Lifecycle</a> page. Please see the section below for workarounds or consider upgrading to a newer and patched version of Rancher.</strong></p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>There are no workarounds for this issue. Users are recommended to upgrade, as soon as possible, to a version of Fleet that contains the fixes.</p>\n<h3 id=\"references\">References</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li>Reach out to the <a href=\"https://github.com/rancher/rancher/security/policy\">SUSE Rancher Security team</a> for security related inquiries.</li>\n<li>Open an issue in the <a href=\"https://github.com/rancher/rancher/issues/new/choose\">Rancher</a> repository.</li>\n<li>Verify with our <a href=\"https://www.suse.com/suse-rancher/support-matrix/all-supported-versions/\">support matrix</a> and <a href=\"https://www.suse.com/lifecycle/\">product support lifecycle</a>.</li>\n</ul>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/rancher/fleet/security/advisories/GHSA-xgpc-q899-67p8\">https://github.com/rancher/fleet/security/advisories/GHSA-xgpc-q899-67p8</a></li>\n<li><a href=\"https://github.com/rancher/fleet/pull/3571\">https://github.com/rancher/fleet/pull/3571</a></li>\n<li><a href=\"https://github.com/rancher/fleet/pull/3572\">https://github.com/rancher/fleet/pull/3572</a></li>\n<li><a href=\"https://github.com/rancher/fleet/pull/3573\">https://github.com/rancher/fleet/pull/3573</a></li>\n<li><a href=\"https://github.com/rancher/fleet/releases/tag/v0.10.12\">https://github.com/rancher/fleet/releases/tag/v0.10.12</a></li>\n<li><a href=\"https://github.com/rancher/fleet/releases/tag/v0.11.7\">https://github.com/rancher/fleet/releases/tag/v0.11.7</a></li>\n<li><a href=\"https://github.com/rancher/fleet/releases/tag/v0.12.2\">https://github.com/rancher/fleet/releases/tag/v0.12.2</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-xgpc-q899-67p8\">https://github.com/advisories/GHSA-xgpc-q899-67p8</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-xgpc-q899-67p8",
            "title": "[github.com/rancher/fleet] Fleet doesn’t validate a server’s certificate when connecting through SSH",
            "date_modified": "2025-04-25T15:11:08.000Z",
            "date_published": "2025-04-25T15:11:07.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-xgpc-q899-67p8"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>A vulnerability has been identified within Fleet where, by default, Fleet will automatically trust a remote server’s certificate when connecting through SSH if the certificate isn’t set in the <code>known_hosts</code> file. This could allow the execution of a man-in-the-middle (MitM) attack against Fleet. In case the server that is being connected to has a trusted entry in the known_hosts file, then Fleet will correctly check the authenticity of the presented certificate. </p>\n<p>Please consult the associated  <a href=\"https://attack.mitre.org/techniques/T1557/\">MITRE ATT&amp;CK - Technique - Adversary-in-the-Middle</a> for further information about this category of attack.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Patched versions include releases <code>v0.10.12</code>, <code>v0.11.7</code> and <code>v0.12.2</code>.</p>\n<p>The fix involves some key areas with the following changes:</p>\n<ul>\n<li><p>Git latest commit fetcher sources <code>known_hosts</code> entries from the following locations, in decreasing order of priority:</p>\n<ol>\n<li>Secret referenced in a <code>GitRepo</code>’s <code>clientSecretName</code> field;</li>\n<li>If no secret is referenced, in a <code>gitcredential</code> secret located in the <code>GitRepo</code>’s namespace;</li>\n<li>If that secret does not exist, in a (new) <code>known-hosts</code> config map installed by Fleet, populated statically with public entries shared by a few git providers: Github, Gitlab, Bitbucket, Azure DevOps;</li>\n</ol>\n</li>\n<li><p>Git cloner: same as above.</p>\n</li>\n<li><p><code>fleet apply</code> command: same as above. The command reads entries from a <code>FLEET_KNOWN_HOSTS</code> environment variable. That command is typically run within a container inside a job pod created by Fleet to update bundles from a new commit. However, users may also decide to run it locally, perhaps even with multiple concurrent executions of the command on the same machine. To cater for this, <code>fleet apply</code> writes the contents of <code>FLEET_KNOWN_HOSTS</code>, if any, to a temporary file with a random name, and deletes that file once bundles have been created. This reduces the risk of conflicts between concurrent runs.\nThis happens regardless of the git repository URL (SSH or not), since a repository may reference artifacts to be retrieved using SSH anyway.</p>\n</li>\n</ul>\n<p><strong>Note about sourcing <code>known_hosts</code> entries:</strong> if entries are found in a supported source, whatever that source may be, then those entries will be used. For instance, if wrong entries, or an incomplete set of entries (e.g. only BitBucket entries for a <code>GitRepo</code> pointing to Github) are found in a secret referenced in a <code>GitRepo</code>’s <code>clientSecretName</code> field, they will still be used. This will lead to errors if strict host key checks are enabled, even if matching, correct entries are found in another source with lower priority, such as the <code>known-hosts</code> config map. Fleet will not use one source to complement the other.</p>\n<p><strong>Note: Fleet v0.9 release line does not have the fix for this CVE. The fix for v0.9 was considered too complex and with the risk of introducing instabilities right before this version goes into end-of-life (EOL), as documented in <a href=\"https://www.suse.com/lifecycle/#suse-rancher-prime\">SUSE’s Product Support Lifecycle</a> page. Please see the section below for workarounds or consider upgrading to a newer and patched version of Rancher.</strong></p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>There are no workarounds for this issue. Users are recommended to upgrade, as soon as possible, to a version of Fleet that contains the fixes.</p>\n<h3 id=\"references\">References</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li>Reach out to the <a href=\"https://github.com/rancher/rancher/security/policy\">SUSE Rancher Security team</a> for security related inquiries.</li>\n<li>Open an issue in the <a href=\"https://github.com/rancher/rancher/issues/new/choose\">Rancher</a> repository.</li>\n<li>Verify with our <a href=\"https://www.suse.com/suse-rancher/support-matrix/all-supported-versions/\">support matrix</a> and <a href=\"https://www.suse.com/lifecycle/\">product support lifecycle</a>.</li>\n</ul>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/rancher/fleet/security/advisories/GHSA-xgpc-q899-67p8\">https://github.com/rancher/fleet/security/advisories/GHSA-xgpc-q899-67p8</a></li>\n<li><a href=\"https://github.com/rancher/fleet/pull/3571\">https://github.com/rancher/fleet/pull/3571</a></li>\n<li><a href=\"https://github.com/rancher/fleet/pull/3572\">https://github.com/rancher/fleet/pull/3572</a></li>\n<li><a href=\"https://github.com/rancher/fleet/pull/3573\">https://github.com/rancher/fleet/pull/3573</a></li>\n<li><a href=\"https://github.com/rancher/fleet/releases/tag/v0.10.12\">https://github.com/rancher/fleet/releases/tag/v0.10.12</a></li>\n<li><a href=\"https://github.com/rancher/fleet/releases/tag/v0.11.7\">https://github.com/rancher/fleet/releases/tag/v0.11.7</a></li>\n<li><a href=\"https://github.com/rancher/fleet/releases/tag/v0.12.2\">https://github.com/rancher/fleet/releases/tag/v0.12.2</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-xgpc-q899-67p8\">https://github.com/advisories/GHSA-xgpc-q899-67p8</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-xgpc-q899-67p8",
            "title": "[github.com/rancher/fleet] Fleet doesn’t validate a server’s certificate when connecting through SSH",
            "date_modified": "2025-04-25T15:11:08.000Z",
            "date_published": "2025-04-25T15:11:07.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-xgpc-q899-67p8"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>A vulnerability has been identified within Fleet where, by default, Fleet will automatically trust a remote server’s certificate when connecting through SSH if the certificate isn’t set in the <code>known_hosts</code> file. This could allow the execution of a man-in-the-middle (MitM) attack against Fleet. In case the server that is being connected to has a trusted entry in the known_hosts file, then Fleet will correctly check the authenticity of the presented certificate. </p>\n<p>Please consult the associated  <a href=\"https://attack.mitre.org/techniques/T1557/\">MITRE ATT&amp;CK - Technique - Adversary-in-the-Middle</a> for further information about this category of attack.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Patched versions include releases <code>v0.10.12</code>, <code>v0.11.7</code> and <code>v0.12.2</code>.</p>\n<p>The fix involves some key areas with the following changes:</p>\n<ul>\n<li><p>Git latest commit fetcher sources <code>known_hosts</code> entries from the following locations, in decreasing order of priority:</p>\n<ol>\n<li>Secret referenced in a <code>GitRepo</code>’s <code>clientSecretName</code> field;</li>\n<li>If no secret is referenced, in a <code>gitcredential</code> secret located in the <code>GitRepo</code>’s namespace;</li>\n<li>If that secret does not exist, in a (new) <code>known-hosts</code> config map installed by Fleet, populated statically with public entries shared by a few git providers: Github, Gitlab, Bitbucket, Azure DevOps;</li>\n</ol>\n</li>\n<li><p>Git cloner: same as above.</p>\n</li>\n<li><p><code>fleet apply</code> command: same as above. The command reads entries from a <code>FLEET_KNOWN_HOSTS</code> environment variable. That command is typically run within a container inside a job pod created by Fleet to update bundles from a new commit. However, users may also decide to run it locally, perhaps even with multiple concurrent executions of the command on the same machine. To cater for this, <code>fleet apply</code> writes the contents of <code>FLEET_KNOWN_HOSTS</code>, if any, to a temporary file with a random name, and deletes that file once bundles have been created. This reduces the risk of conflicts between concurrent runs.\nThis happens regardless of the git repository URL (SSH or not), since a repository may reference artifacts to be retrieved using SSH anyway.</p>\n</li>\n</ul>\n<p><strong>Note about sourcing <code>known_hosts</code> entries:</strong> if entries are found in a supported source, whatever that source may be, then those entries will be used. For instance, if wrong entries, or an incomplete set of entries (e.g. only BitBucket entries for a <code>GitRepo</code> pointing to Github) are found in a secret referenced in a <code>GitRepo</code>’s <code>clientSecretName</code> field, they will still be used. This will lead to errors if strict host key checks are enabled, even if matching, correct entries are found in another source with lower priority, such as the <code>known-hosts</code> config map. Fleet will not use one source to complement the other.</p>\n<p><strong>Note: Fleet v0.9 release line does not have the fix for this CVE. The fix for v0.9 was considered too complex and with the risk of introducing instabilities right before this version goes into end-of-life (EOL), as documented in <a href=\"https://www.suse.com/lifecycle/#suse-rancher-prime\">SUSE’s Product Support Lifecycle</a> page. Please see the section below for workarounds or consider upgrading to a newer and patched version of Rancher.</strong></p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>There are no workarounds for this issue. Users are recommended to upgrade, as soon as possible, to a version of Fleet that contains the fixes.</p>\n<h3 id=\"references\">References</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li>Reach out to the <a href=\"https://github.com/rancher/rancher/security/policy\">SUSE Rancher Security team</a> for security related inquiries.</li>\n<li>Open an issue in the <a href=\"https://github.com/rancher/rancher/issues/new/choose\">Rancher</a> repository.</li>\n<li>Verify with our <a href=\"https://www.suse.com/suse-rancher/support-matrix/all-supported-versions/\">support matrix</a> and <a href=\"https://www.suse.com/lifecycle/\">product support lifecycle</a>.</li>\n</ul>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/rancher/fleet/security/advisories/GHSA-xgpc-q899-67p8\">https://github.com/rancher/fleet/security/advisories/GHSA-xgpc-q899-67p8</a></li>\n<li><a href=\"https://github.com/rancher/fleet/pull/3571\">https://github.com/rancher/fleet/pull/3571</a></li>\n<li><a href=\"https://github.com/rancher/fleet/pull/3572\">https://github.com/rancher/fleet/pull/3572</a></li>\n<li><a href=\"https://github.com/rancher/fleet/pull/3573\">https://github.com/rancher/fleet/pull/3573</a></li>\n<li><a href=\"https://github.com/rancher/fleet/releases/tag/v0.10.12\">https://github.com/rancher/fleet/releases/tag/v0.10.12</a></li>\n<li><a href=\"https://github.com/rancher/fleet/releases/tag/v0.11.7\">https://github.com/rancher/fleet/releases/tag/v0.11.7</a></li>\n<li><a href=\"https://github.com/rancher/fleet/releases/tag/v0.12.2\">https://github.com/rancher/fleet/releases/tag/v0.12.2</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-xgpc-q899-67p8\">https://github.com/advisories/GHSA-xgpc-q899-67p8</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-xgpc-q899-67p8",
            "title": "[github.com/rancher/fleet] Fleet doesn’t validate a server’s certificate when connecting through SSH",
            "date_modified": "2025-04-25T15:11:08.000Z",
            "date_published": "2025-04-25T15:11:07.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-xgpc-q899-67p8"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>A vulnerability has been identified within Rancher where a user with the ability to create a project, on a certain cluster, can create a project with the same name as an existing project in a different cluster. This results in the user gaining access to the other project in the different cluster, resulting in a privilege escalation. This happens because the namespace used on the local cluster to store related resources (PRTBs and secrets) is the name of the project.</p>\n<p>Please consult the associated  <a href=\"https://attack.mitre.org/tactics/TA0004/\">MITRE ATT&amp;CK - Technique - Privilege Escalation</a> for further information about this category of attack.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Patched versions include releases <code>v2.11.1</code>, <code>v2.10.5</code>, <code>v2.9.9</code>.</p>\n<p>The fix involves the following changes:</p>\n<p><strong>Rancher:</strong></p>\n<ul>\n<li>Instead of using the project name as the namespace, Rancher will instead be using a new field on the project spec called backingNamespace. If that field exists, use that for the project namespace going forward. However, if the project does not have that field filled out (likely because it existed before this change), Rancher will continue using the name for the namespace.</li>\n</ul>\n<p><strong>Rancher Webhook:</strong></p>\n<ul>\n<li>New mutation on create <code>project.Status.BackingNamespace</code> to be <code>SafeConcatName(project.Spec.ClusterName, project.Name)</code>;</li>\n<li>Generate the name manually within the mutating webhook, because normally, name generation happens after the mutating webhooks;</li>\n<li>Removed a validation where <code>projectName</code> and <code>Namespace</code> had to be the same for PRTBs, since PRTBs now go in <code>project.BackingNamespace</code>;</li>\n<li>On update, if <code>BackingNamespace</code> isn't set, set it to <code>project.Name</code>. For existing objects after update this will help unify them to the new projects.</li>\n<li>The <code>BackingNamespace</code> can't be edited after it's set.</li>\n</ul>\n<p><strong>Note: Rancher v2.8 release line does not have the fix for this CVE. The fix for v2.8 was considered too complex and with the risk of introducing instabilities right before this version goes into end-of-life (EOL), as documented in <a href=\"https://www.suse.com/lifecycle/#suse-rancher-prime\">SUSE’s Product Support Lifecycle</a> page. Please see the section below for workarounds or consider upgrading to a newer and patched version of Rancher.</strong></p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>If you can't upgrade to a fixed version, please make sure that:</p>\n<ul>\n<li>Users are not allowed to create projects with the same object names from another cluster.</li>\n</ul>\n<p>To identify if this security issue could have been abused within your system, you need to find if there are any projects with the same name but on different clusters. To do that, run the following command in the local cluster as an administrator:</p>\n<pre><code>kubectl get projects -A -o=custom-columns='NAME:metadata.name' | sort | uniq -c\n</code></pre>\n<p>That command will list all project names, and show the instances of each name. Any project with more than 1 instance is affected by this security issue. To remedy the situation, the projects will need to be deleted and re-created to ensure no namespace collisions happen. While it would be possible to delete all but 1 of the projects with the same name, this is unadvisable because a user could have given themselves access to the wrong project.</p>\n<h3 id=\"references\">References</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li>Reach out to the <a href=\"https://github.com/rancher/rancher/security/policy\">SUSE Rancher Security team</a> for security related inquiries.</li>\n<li>Open an issue in the <a href=\"https://github.com/rancher/rancher/issues/new/choose\">Rancher</a> repository.</li>\n<li>Verify with our <a href=\"https://www.suse.com/suse-rancher/support-matrix/all-supported-versions/\">support matrix</a> and <a href=\"https://www.suse.com/lifecycle/\">product support lifecycle</a>.</li>\n</ul>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/rancher/rancher/security/advisories/GHSA-8h6m-wv39-239m\">https://github.com/rancher/rancher/security/advisories/GHSA-8h6m-wv39-239m</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-8h6m-wv39-239m\">https://github.com/advisories/GHSA-8h6m-wv39-239m</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-8h6m-wv39-239m",
            "title": "[github.com/rancher/rancher] Rancher users who can create Projects can gain access to arbitrary projects",
            "date_modified": "2025-04-25T15:09:27.000Z",
            "date_published": "2025-04-25T15:09:26.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-8h6m-wv39-239m"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>A vulnerability has been identified within Rancher where a user with the ability to create a project, on a certain cluster, can create a project with the same name as an existing project in a different cluster. This results in the user gaining access to the other project in the different cluster, resulting in a privilege escalation. This happens because the namespace used on the local cluster to store related resources (PRTBs and secrets) is the name of the project.</p>\n<p>Please consult the associated  <a href=\"https://attack.mitre.org/tactics/TA0004/\">MITRE ATT&amp;CK - Technique - Privilege Escalation</a> for further information about this category of attack.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Patched versions include releases <code>v2.11.1</code>, <code>v2.10.5</code>, <code>v2.9.9</code>.</p>\n<p>The fix involves the following changes:</p>\n<p><strong>Rancher:</strong></p>\n<ul>\n<li>Instead of using the project name as the namespace, Rancher will instead be using a new field on the project spec called backingNamespace. If that field exists, use that for the project namespace going forward. However, if the project does not have that field filled out (likely because it existed before this change), Rancher will continue using the name for the namespace.</li>\n</ul>\n<p><strong>Rancher Webhook:</strong></p>\n<ul>\n<li>New mutation on create <code>project.Status.BackingNamespace</code> to be <code>SafeConcatName(project.Spec.ClusterName, project.Name)</code>;</li>\n<li>Generate the name manually within the mutating webhook, because normally, name generation happens after the mutating webhooks;</li>\n<li>Removed a validation where <code>projectName</code> and <code>Namespace</code> had to be the same for PRTBs, since PRTBs now go in <code>project.BackingNamespace</code>;</li>\n<li>On update, if <code>BackingNamespace</code> isn't set, set it to <code>project.Name</code>. For existing objects after update this will help unify them to the new projects.</li>\n<li>The <code>BackingNamespace</code> can't be edited after it's set.</li>\n</ul>\n<p><strong>Note: Rancher v2.8 release line does not have the fix for this CVE. The fix for v2.8 was considered too complex and with the risk of introducing instabilities right before this version goes into end-of-life (EOL), as documented in <a href=\"https://www.suse.com/lifecycle/#suse-rancher-prime\">SUSE’s Product Support Lifecycle</a> page. Please see the section below for workarounds or consider upgrading to a newer and patched version of Rancher.</strong></p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>If you can't upgrade to a fixed version, please make sure that:</p>\n<ul>\n<li>Users are not allowed to create projects with the same object names from another cluster.</li>\n</ul>\n<p>To identify if this security issue could have been abused within your system, you need to find if there are any projects with the same name but on different clusters. To do that, run the following command in the local cluster as an administrator:</p>\n<pre><code>kubectl get projects -A -o=custom-columns='NAME:metadata.name' | sort | uniq -c\n</code></pre>\n<p>That command will list all project names, and show the instances of each name. Any project with more than 1 instance is affected by this security issue. To remedy the situation, the projects will need to be deleted and re-created to ensure no namespace collisions happen. While it would be possible to delete all but 1 of the projects with the same name, this is unadvisable because a user could have given themselves access to the wrong project.</p>\n<h3 id=\"references\">References</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li>Reach out to the <a href=\"https://github.com/rancher/rancher/security/policy\">SUSE Rancher Security team</a> for security related inquiries.</li>\n<li>Open an issue in the <a href=\"https://github.com/rancher/rancher/issues/new/choose\">Rancher</a> repository.</li>\n<li>Verify with our <a href=\"https://www.suse.com/suse-rancher/support-matrix/all-supported-versions/\">support matrix</a> and <a href=\"https://www.suse.com/lifecycle/\">product support lifecycle</a>.</li>\n</ul>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/rancher/rancher/security/advisories/GHSA-8h6m-wv39-239m\">https://github.com/rancher/rancher/security/advisories/GHSA-8h6m-wv39-239m</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-8h6m-wv39-239m\">https://github.com/advisories/GHSA-8h6m-wv39-239m</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-8h6m-wv39-239m",
            "title": "[github.com/rancher/rancher] Rancher users who can create Projects can gain access to arbitrary projects",
            "date_modified": "2025-04-25T15:09:27.000Z",
            "date_published": "2025-04-25T15:09:26.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-8h6m-wv39-239m"
            },
            "tags": [
                "severity"
            ]
        }
    ]
}